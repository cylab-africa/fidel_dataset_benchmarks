{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import yaml\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 16:08:26.994171: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-13 16:08:27.034391: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-13 16:08:27.729831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), '..')), \"config/main.yaml\")\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "DATASET_PATH =config[\"DATASET_PATH\"]\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, path_file, preprocessor):\n",
    "\n",
    "        self.data =  pd.read_csv(path_file)\n",
    "        self.preprocessor = preprocessor\n",
    "        self.n_data_points = len(self.data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_data_points\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.data.iloc[idx]\n",
    "        image = Image.open(row[\"images\"]).convert(\"RGB\")\n",
    "        text = row[\"text\"]\n",
    "        pixel_values = self.preprocessor(image, return_tensors=\"pt\").pixel_values\n",
    "        text = self.preprocessor.tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        return pixel_values, text\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.idx = 0\n",
    "        return self  \n",
    "\n",
    "    def __next__(self):\n",
    "        if self.idx >= self.n_data_points:\n",
    "            self.idx = 0\n",
    "            raise StopIteration\n",
    "        self.idx += 1\n",
    "        return self[self.idx] ## calling the \n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        print(batch[0][1].shape,batch[5][1].shape )\n",
    "        images  = torch.cat([data[0] for data in batch ], dim=0)\n",
    "        max_length = max(len(seq) for seq in batch[1])\n",
    "        # padded_input_ids = torch.tensor([data[1].tolist() + [self.preprocessor.tokenizer.pad_token_id] * (max_length - len(data)) for data in batch])\n",
    "        padded_input_ids = torch.nn.utils.rnn.pad_sequence([data[1].squeeze(0) for data in batch],batch_first=True, padding_value=self.preprocessor.tokenizer.pad_token_id)\n",
    "        return images, padded_input_ids\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3]) torch.Size([1, 3])\n",
      "torch.Size([8, 3, 384, 384]) ['14', '27/04/2000', '02/11/1988', 'Bisrat Getachew Tesfaye', '2', '22', 'Almaz@gmail.com', '-']\n"
     ]
    }
   ],
   "source": [
    "data = Dataloader(DATASET_PATH, preprocessor=processor)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = data,\n",
    "    batch_size  = config['BATCH_SIZE'],\n",
    "    shuffle     = True,\n",
    "    collate_fn= data.collate_fn\n",
    "    )\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch[0].shape, processor.tokenizer.batch_decode(batch[1], skip_special_tokens=True))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
