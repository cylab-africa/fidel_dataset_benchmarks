{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/datagen/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config {'SCENARIO': 1, 'DATASET_PATH': '/data/synthetic_data/labels/output_labels.csv', 'TRAIN_PATH': '/data/synthetic_data/labels/output_labels_train.csv', 'VAL_PATH': '/data/synthetic_data/labels/output_labels_test.csv', 'BATCH_SIZE': 64, 'MODEL_ID': 'microsoft/trocr-base-handwritten', 'EPOCHS': 100, 'batch_size': 256, 'enc_dropout': 0.2, 'enc_num_layers': 1, 'enc_num_heads': 1, 'dec_dropout': 0.2, 'dec_num_layers': 4, 'dec_num_heads': 4, 'd_model': 512, 'd_ff': 2048, 'learning_rate': '1E-4', 'optimizer': 'AdamW', 'momentum': 0.0, 'nesterov': True, 'scheduler': 'CosineAnnealing', 'factor': 0.9, 'patience': 6, 'epochs': 100, 'Name': 'blessed'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataset.dataloader import MyOcrDataloader, MyCustomOcrDataloader\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import yaml\n",
    "import wandb\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import gc\n",
    "from utils.utils import *\n",
    "from utils.charactertokenizer import CharacterTokenizer\n",
    "from jiwer import wer, cer\n",
    "from models.models import TrOCRMyDecoder\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26557\n"
     ]
    }
   ],
   "source": [
    "typed =pd.read_csv(\"/data/line_mapping_merged.csv\")\n",
    "print(len(typed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34435\n"
     ]
    }
   ],
   "source": [
    "hand =pd.read_csv(\"/data/handwritten_line_mapping_merged.csv\")\n",
    "print(len(hand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), '..')), \"config/main.yaml\")\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "DATASET_PATH =config[\"DATASET_PATH\"]\n",
    "TRAIN_PATH =config[\"TRAIN_PATH\"]\n",
    "VAL_PATH =config[\"VAL_PATH\"]\n",
    "\n",
    "\n",
    "MODEL_ID = config[\"MODEL_ID\"]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = TrOCRProcessor.from_pretrained(MODEL_ID)\n",
    "# model =VisionEncoderDecoderModel.from_pretrained(MODEL_ID).to(device)\n",
    "# model.config.decoder_start_token_id = processor.tokenizer.eos_token_id\n",
    "# model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "# model.config.vocab_size = model.config.decoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 3, 384, 384]) torch.Size([64, 118]) ['ተባበሩ ወይ ተሰባበሩ ኢትዮጵያዊነት እና ብሄርተኝነት::', 'እንደሪፖርተር ጋዜጣ ዘገባ ተማሪዎቹ ያቀረቡት የተቃውሞ ደብዳቤ ለአንድ ሳምንት ምላሽ ስለተነፈገው መጋቢት ቀን ዓ ም ፓትርያርኩ በሚያስቀድሱበት በመንበረ ፓትርያርክ ቅድስተ', 'የኤሌክትሪክ ቡድን ይህን አጋጣሚ ተጠቅሞ ከመቻልና ከኦሜድላ ጠንካራ ተጫዋቾችን በመውሰድ ከዓም ጀምሮ ጊዮርጊስ ቡድን ጋር ጠንካራ ተፎካካሪ ለመሆን በቃ::', 'ይሁን ማቀዝቀዣ ወዘተ የሚያስፈልገው ኃይል የራሱ የሆነ ተጽእኖ አለው እንደ ማመንጫው አይነት ከልቀት ጋር የሚያያዘው ተጽእኖ በተለያየ መልኩ ሊገለጽ ይችላል', 'የእስራኤል ብሔር የተደራጀበት መንገድ ምን ጥያቄ ይነሳል::', 'ትቀልዳለህ እንዴ ብዬ እንዳልጠይቀው መንገዱን ዘጋብኝ::', 'ነበረባቸው የወያኔ አገዛዝ ግን ከማርክሲዝም ጋር የተሰናበተው በመጀመሪያ ደረጃ ጫካ ውሰጥ ሆኖ ሰው መግደል ሲጀምር ሲሆን በሁለተኛ ደረጃ ደግሞ ስልጣን', 'ቀጥሎ የተወለደችው ማህደር ግን ጉዳት አልባ ሆና ተወለደች የማህደር ጉዳት አልባ መሆን ለወላጆቿ ትልቅ የምስራች ቢሆንም ለሷ ግን ጫናው የበረታባት', 'ዲሞክራሲ ሲተረጎም ለህገ መንግስት የቆመ ዜጋ ማደንና ማሳደድ ማለት ከሆነ::', 'በምሥራቅ ሸዋ ዞን የምትገኝና በአትክልትና ፍራፍሬ ምርት የምትታወቅ ወረዳ ነች::', 'ብይን ለመስጠት ለነሐሴ ቀን ዓ ም ቀጠሮ ሰጥቷል::', 'ከአክብሮት አንጻር ሊሆን ይችላል እንጂ የፈረንጅ አምላኪነት ልክፍት ይዟቸዋል ብዬ አልገምትም በተለያዩ ፈረንጅ አገር ያሉ ኢትዮጵያዊያን እዚህ ለነሱ የሚደረግላቸውን አክብሮት', 'በሊቢያና ሶርያ ላይ አጀንዳ ያላቸው ምዕራባውያን የአረብ ጸደይ ከቁጥጥራቸው በመውጣት በግብጽ ላይ እንደተከሰተው ሁሉ ወደሌሎች ወዳጅ አረብና የመካከለኛው ምስራቅ አገራት', 'በኮሌጅ ማለፊያ ውጤታቸው የወደቁ ተማሪዎችን በመቀበል ገንዘብ ተኮር የትምህርት አሰጣጥና የፈተና ዘዴን በመከተል የትውልድ ውድቀትን የማያጤኑ ብዙ ስግብግቦች ያሉባት አገር', 'ጌታ ደቀ መዛሙርቱን ያስተማራቸው የሚናገረውን በተግባር እያደረገ ጭምር ነው::', 'ሁልጊዜ ከጠላፊው ጋር ወደ ስብሰባ አይመጣም የፆታ ዝንባሌ ወይም ወሲባዊ ይዘት ያላቸው ፊልሞች ጋር የሚያካሂዱ አንዳንድ ሰለባ ምስሎች ይላኩ ይህም', 'አቡነ ጳውሎስ ሰውና ወንድም በመኾናቸው ዕረፍታቸው በጣም ያሳዝነናል ያሳዝነኛል ትተውልን የሄዱት ቤተ ክርስቲያንና ጳጳሳቱ ደኅና ኹና መሪዎቿም አንድነታቸውን ጠብቀው ብቃታቸው', 'ጌታቸው ግን ከኅዳር ጀመሮ የአንድ ዓመት ቅጣቱን እስር እያወራረደ ነው ጌታቸው የታሰረው ቤተሰቦቹ ከሚኖሩበት አዲስ አበባ ኪሜ ርቃ በምትገኘው ሸዋ', 'ሁለተኞቹ ወገኖች ሰፈሩን ዙሪያውን ከበን እንያዘው ተባባሉ የሞገደኛውን ቤት ከበቡ እንደተከበበ ያወቀው ወጣት እቤቱ አጠገብ ካለ ትልቅ ባህር ዛፍ ላይ', 'ሁለት እስረኞች በድብደባ ህይወታቸው እንዳለፈ የአይን እማኞች ለፍርድ ቤት ገለፁ::', 'የኢሕአዴግ ታጋዮች የመንግሥት ጠንካራ ይዞታ የሚባሉ ከተሞችን ሳይቀር መቆጣጠር ችለዋል ወደ አዲስ አበባም የሚያደርጉት ግሥጋሴም ፕሬዝዳንት መንግሥቱ ኃይለ ማርያምን ሳይቀር', 'በልማት የበለጸጉ ናቸው ጸሎት ብቻ እያደረሰ ስራ ፈትቶ የሚቀመጥ መነኩሴ የለም በኢትዮጵያ የጥንታዊው ዘመን ውስጥ በሥነ ጽሑፍና ኪነ ሕንጻ ላይ', 'የምድር ባቡር ኩባንያ የ ዓመት እቅድ::', 'ሰደፍም ደበደቡኝ እጅግ አስፈሪ ነው ወደ ሶማሊያ መመለስ አልሻም በዚህ ምንም የለኝም ብታመም እንኳ ህክምና አላገኝም የምግብ እደላው ለእኔ እና', 'ሩዋንዳ የምስራቅና መካከለኛው አፍሪካ ወይም ሴካፋን አዘጋጅታ ነበር ሩዋንዳ ባዘጋጀችው የሴቶች የምስራቅ አፍሪካ አገራት ውድድር ለአሸናፊው ጉርሻ ለተሸናፊው ደግሞ ሽረት', 'አንድነት ደግሞ ምን ዓይነት አስተሳሰቦችና ምን ዓይነት የወደፊት ዕቅዶች አሉት::', 'እየጠቀስክ የምትፅፈው አልተመቸኝም ይሄ ብዙ ቦታ አለ ሰልችቶናል እሱን ስሜትህን ተወው በተረፈ ጎበዝ ሳይኮሎጂስት ነህ::', 'በሁለቱም ጥቃቶች በሰው ላይ የደረሰ ጉዳት የለም ተብሏል::', 'ችግሩ ሀገራዊ ገጽታ ላይም የሚያሳድረው ተጽዕኖ ቀላል የሚባል አይሆንም::', 'ቤት ባለስልጣናት ግን ለነዚህ ግለሰቦች የነፃ ፍቃድ በመስጠት መሰል ሀላፊነት የማይሰማቸው ሰዎች ነገም ተመሳሳይ ታሪክ እንዲደግሙ በማበረታታቸው የተሰማንን ቅሬታ እንገልፃለን::', 'ሲባክን በማየት ዝምታን የመረጡ የምክርቤቱ አባላት ችግሩን አያውቁት ይሆን በማለት የሚጠይቁ ሠራተኞችም በራሳቸው በመድረክ ማንሳት ይኖርባቸዋል ፓርላማው ሌላውን አስፈፃሚ አካል', 'ያቀረቡት መሆኑን አስገንዝበውናል::', 'ፍፁም ዛሬ በኢትዮጵያ የምድር ባቡር ኮርፖሬሽን ማህንዲስ ሲሆን ሰላማዊት ደግሞ የልብስ ነዳፊ ወይም ዲዛይነር ናት::', 'እንዲህም ይሆናል እግዚአብሔር እንደ ተናገረ ወደ ሚሰጣችሁ አገር በገባችሁ ጊዜ ይህን አምልኮ ጠብቁት::', 'እውነቱን ብናገር እታሰራለሁ እገደላለሁ ከሥራ ብባረር ልጆቼና ቤተ ሰቦቼ ምን ይበላሉ የሚለው ሐሳብ በሳቸው ሕሊና አይታሰብም::', 'ውል ሕጉ ያዛቸዋል ከደንበኛው ጋር ውል ሲገቡ አገልግሎቱን ላያቆሙ ካቆሙ ግን ቀድመው ሊያሳውቁ ነው ይህ ቀላል የንግድ ውል ሕግ በተቃወሰው', 'ይችላሉ እኛ በሚገባ ያልጨበጥነውን ወይም ያላስተዋልነውን ጸሎትም ደግሞ ጠቃሚ ነው እንዴት መንፈሳዊ ስጦታ እንደሚሰጠን በትክክል የሚያውቀው አንዱ አካል ስጦታ ሰጪው', 'አባት መሆን ተፈታታኝ ነው አይደል::', 'እ ኤ አ በኢትዮጵያ ረሃብ የሚጀምረበት ወይም ደግሞ እነርሱ በተለያየ ስያሜ እንደሚጠሩት አሰቃቂ የምግብ ቀውስ እንደሚከሰት ግልጽ ሆኖልኝ ነበር::', 'ተለት ሲባባስ እንጂ መፍትሔ ሲያገኝ አልታየም ከኢትዮጵያ ወደ ጅቡቲ ለተዘረጋው የባቡር አገልግሎት የሚፈለገውን ኃይል ማቅረብ ባለመቻሉ የድንጋይ ከሰል በአማራጭነት ለመጠቀም', 'ወራት አፈጻጸም ገምግሞ ቀጣይ አቅጣጫ ያስቀምጣል ተብሎ ይጠበቃል::', 'ፖለቲካ በደም አይጋባም አርበኞች ግንቦት ኢዲቶርያል::', 'ያለውን ፓርቲ መውቀስን እንደ ሁነኛ የፓርቲ ስራ ማየታቸው ነው::', 'ኢውፕሲሎን ለማመልከት ተጠቀመ::', 'እንዲያ ነው::', 'ጥያቄዎችህን ለመመለስ ምንም መረጃ የለኝም ስሜም ተድላ ሀይሉ እንጂ ሀይሉ አይደለም::', 'ሥዕሎችና በዚህ ዝርዝር ላይ ያልተካተቱ ሌሎች ከጉባኤው ዓላማ ጋር የሚሄዱ ርእሶችም እንደሚቅቡ ገልጸውልናል::', 'ዜና ከሚመለከተው ወገን እስካሁን በይፋ ማረጋገጫ አላገኘም::', 'በተቋሙ የብድር ንዑስ የሥራ ሂደት ባለቤት አቶ ሽመልስ ደበሌ ለዋልታ ኢንፎርሜሽን ማዕከል እንዳስታወቁት ብድሩ የተሰጠው በተቋሙ ቀርበው የብድር ጥያቄ ላቀረቡ', 'የአድዋን የአንድ ቀን ጦርነት በድል ለመፈጸም መረጃዎች ወሳኝ እንደነበሩ ይታወቃል በረቀቀ የጦርነት ጥበብና ወታደራዊ ታክቲኮች ከሁሉም የኢትዮጵያ ጠላቶች ልቀው የተገኙት', 'ደረጃ ላይ የሚገኙት የህብረተሰብ ክፍሎች በሃገራቸው የወደፊት ኢኮኖሚ እደገት ትልቅ ተስፋ አላቸውና አይናቸውን ወደ ውጭ ከመጣል ይልቅ ሃገራቸው መቆየቱን መርጠዋል', 'ሰንደቅ የአመራር ምርጫው በምን መልኩ ተከናወነ::', 'ለአይነት የስኳር በሽታ ይጋለጣሉ ተመራማሪዎች::', 'እየተቃወምኩኝ አይደለም የእውቀታችሁን ደረጃ እንጂደግሞ ታሪክ ሰሪው እግዚአብሔር እንጂ ሲኖዶስ አይደለም ታዲያ እልልታችሁና ደስታችሁ ለእግዚአብሔር ወይስ ለሲኖዶሱ ለመላው የተዋህዶ ልጆች', 'ሰከን ባለ መልኩ ለአካባቢው እድገትና ብልጽግና ቅድሚያ በመስጠት የተፈጠረውን አንገት የሚያስደፋ አሉታዊ ገጽታ በያገባኛል ስሜት በህብረት ማስወገድ እንዳለብንና ለዚህም ወልድያወዳዶች', 'የጠቅላይ ቤተ ክህነት የቁጥጥር አገልግሎት ክፍል ማኅበሩ የጠቅላይ ቤተ ክህነት ደረሰኝን ለምን አይጠቀምም በሚል ጥያቄ አንስቷል::', 'ሁኔታው ሰፍሮ ወደ ፍትሕ እንሄዳለን ጉዳዩ እጅግ በጣም ፈታኝ ነው እኛም ተከራዮች ነንእሱም ተከራይቶ የሚኖር ነው ወደፊት እንዴት እንደምናደርግ አላውቅም', 'ኢትዮጵያውያን አትሌቶች በወንዶችም በሴቶችም ድል ቀንቷቸዋል ሂውስተን አሜሪካ ውስጥ በተደረገው የማራቶን ሩጫ ብርሃኑ ደገፋ በማስመዝገብ ጌቦ ቡርቃ በኹለተኛ ወጥቷል በሦስተኛ', 'ይህንኑ ቶልስቶይን ተመርኩዘህ የጻፍህልንን ጠቃሚ ታሪክ እንደሚነግረን አምናለሁ አዳምና ሔዋን የበደሉት በደልም ዓለምን መውደድ እንደኾነ ይሰማኛል የተሰጣቸው አልበቃቸው ብሎ ሰጪውን', 'ጥያቄ በየቀጠሮው ዳኞች እተቀያየሩ መቅረባቸው አሁን ተስፋ የሚያደርጉት ነገር ላይ ተጽእኖ አይፈጥርም ጠበቃ አምሐ አይፈጥርም በማለት መናገር አልችልም::', 'በዚህ ሁሉ ሂደት የኢህአዴግ አስተዋጽኦ ምንድነው::', 'ኤርትራ ከኢትዮጵያ ለተሰነዘረባት ጥቃት አፀፋ ለመመለስ እንደማትሻ አመለከተች የሐገሪቱ የዉጭ ጉዳይ ሚኒስትር በሰጡት መግለጫ መንግስታቸዉ የኢትዮጵያ መንግስት ይህን ጥቃት የሰነዘረዉ', 'ከዚያም በማሰባሰብና በማስታጠቅ በጭልጋና በመተማ ወረዳ በማሰማራት ግጭቱ በሁለቱ ህዝቦች መካከል የተደረገ ለማስመሰል ሞክረዋል በተወሰነ ደረጃም ቢሆን ዓላማቸው ተሳክቶላቸዋል ዛሬ', 'ከዚህ ዘመን ጋር የሚስተካከሉ ታሪካዊ ወቅቶች ካሉም የአህመድ ግራኝ ዘመንና የ ዓ ም የነበረው የወረራ ዘመናት ናቸው::']\n"
     ]
    }
   ],
   "source": [
    "## sanity check for data loader\n",
    "os.chdir(\"../dataset\")\n",
    "tokenizer = CharacterTokenizer.from_pretrained('/home/ubuntu/HandWritten_Amharic_English_OCR/Amharic_Char_Tokenizer2')\n",
    "train_data = MyCustomOcrDataloader(TRAIN_PATH, preprocessor=processor, tokenizer  = tokenizer, img_root='/data/synthetic_data/data')\n",
    "val_data = MyCustomOcrDataloader(VAL_PATH, preprocessor=processor, tokenizer  = tokenizer, img_root='/data/synthetic_data/data')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = train_data,\n",
    "    batch_size  = config['BATCH_SIZE'],\n",
    "    shuffle     = True,\n",
    "    collate_fn= train_data.collate_fn\n",
    "    )\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch[0].shape, batch[1].shape,tokenizer.batch_decode(batch[1], skip_special_tokens=True))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Train Images   :  5000\n",
      "Batch Size           :  64\n",
      "Train Batches        :  79\n",
      "Val Batches          :  79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader    = torch.utils.data.DataLoader(\n",
    "    dataset     = train_data,\n",
    "    batch_size  = config[\"batch_size\"],\n",
    "    shuffle     = True,\n",
    "    num_workers = 4,\n",
    "    pin_memory  = True,\n",
    "    collate_fn  = train_data.collate_fn\n",
    ")\n",
    "\n",
    "val_loader      = torch.utils.data.DataLoader(\n",
    "    dataset     = val_data,\n",
    "    batch_size  = config[\"batch_size\"],\n",
    "    shuffle     = False,\n",
    "    num_workers = 2,\n",
    "    pin_memory  = True,\n",
    "    collate_fn  = train_data.collate_fn,\n",
    ")\n",
    "\n",
    "print(\"No. of Train Images   : \", train_data.__len__())\n",
    "print(\"Batch Size           : \", config[\"batch_size\"])\n",
    "print(\"Train Batches        : \", train_loader.__len__())\n",
    "print(\"Val Batches          : \", val_loader.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Shapes of the Data --\n",
      "\n",
      "x_pad shape:\t\ttorch.Size([64, 1, 3, 384, 384])\n",
      "x_len shape:\t\ttorch.Size([64])\n",
      "\n",
      "y_shifted_pad shape:\ttorch.Size([64, 110])\n",
      "y_golden_pad shape:\ttorch.Size([64, 110])\n",
      "y_len shape:\t\ttorch.Size([64])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Sanity Check '''\n",
    "\n",
    "print(\"Checking the Shapes of the Data --\\n\")\n",
    "\n",
    "for batch in train_loader:\n",
    "    x_pad, y_shifted_pad, y_golden_pad, x_len, y_len, = batch\n",
    "\n",
    "    print(f\"x_pad shape:\\t\\t{x_pad.shape}\")\n",
    "    print(f\"x_len shape:\\t\\t{x_len.shape}\\n\")\n",
    "\n",
    "    print(f\"y_shifted_pad shape:\\t{y_shifted_pad.shape}\")\n",
    "    print(f\"y_golden_pad shape:\\t{y_golden_pad.shape}\")\n",
    "    print(f\"y_len shape:\\t\\t{y_len.shape}\\n\")\n",
    "\n",
    "    # print(y_shifted_pad)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.1\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Model Parameters:\n",
      " 104.215895\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "''' Please refer to the config file and top sections to fill in the following '''\n",
    "\n",
    "model = TrOCRMyDecoder(\n",
    "input_dim                   = None,\n",
    "dec_num_layers              = config[\"dec_num_layers\"],\n",
    "dec_num_heads               = config[\"dec_num_heads\"],\n",
    "\n",
    "d_model                     = config[\"d_model\"],\n",
    "d_ff                        = config[\"d_ff\"],\n",
    "\n",
    "target_vocab_size           = tokenizer.vocab_size,\n",
    "eos_token                   = tokenizer.eos_token_id,\n",
    "sos_token                   = tokenizer.bos_token_id,\n",
    "pad_token                   = tokenizer.pad_token_id,\n",
    "\n",
    "enc_dropout                 = config[\"enc_dropout\"],\n",
    "dec_dropout                 = config[\"enc_dropout\"],\n",
    "\n",
    "# decrease to a small number if you are just trying to implement the network\n",
    "max_seq_length              = 200 , # Max sequence length for transcripts. Check data verification.\n",
    ").to(device)\n",
    "\n",
    "def num_parameters(mode):\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params / 1E6\n",
    "\n",
    "para = num_parameters(model)\n",
    "print(\"#\"*10)\n",
    "print(f\"Model Parameters:\\n {para}\")\n",
    "print(\"#\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc=\"Train\")\n",
    "\n",
    "    total_loss          = 0\n",
    "    running_loss        = 0.0\n",
    "    running_perplexity  = 0.0\n",
    "\n",
    "    for i, (inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs          = inputs.to(device)\n",
    "        targets_shifted = targets_shifted.to(device)\n",
    "        targets_golden  = targets_golden.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # passing the minibatch through the model\n",
    "            # raw_predictions, attention_weights = model(inputs, inputs_lengths, targets_shifted, targets_lengths)\n",
    "            raw_predictions, attention_weights = model(inputs, inputs_lengths, targets_shifted, targets_lengths)\n",
    "\n",
    "\n",
    "            padding_mask = torch.logical_not(torch.eq(targets_shifted, tokenizer.pad_token_id))\n",
    "\n",
    "            # cast the mask to float32\n",
    "            padding_mask = padding_mask.float()\n",
    "            loss = loss_func(raw_predictions.transpose(1,2), targets_golden)*padding_mask\n",
    "            loss = loss.sum() / padding_mask.sum()\n",
    "\n",
    "        scaler.scale(loss).backward()   # This is a replacement for loss.backward()\n",
    "        scaler.step(optimizer)          # This is a replacement for optimizer.step()\n",
    "        scaler.update()                 # This is something added just for FP16\n",
    "\n",
    "        running_loss        += float(loss.item())\n",
    "        perplexity          = torch.exp(loss)\n",
    "        running_perplexity  += perplexity.item()\n",
    "\n",
    "        # online training monitoring\n",
    "        batch_bar.set_postfix(\n",
    "            loss = \"{:.04f}\".format(float(running_loss / (i + 1))),\n",
    "            perplexity = \"{:.04f}\".format(float(running_perplexity / (i + 1)))\n",
    "        )\n",
    "\n",
    "        batch_bar.update()\n",
    "\n",
    "        del inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    running_loss        = float(running_loss / len(train_loader))\n",
    "    running_perplexity  = float(running_perplexity / len(train_loader))\n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    return running_loss, running_perplexity, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_fast(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    # progress bar\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc=\"Val\", ncols=5)\n",
    "\n",
    "    running_distance = 0.0\n",
    "\n",
    "    for i, (inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths) in enumerate(dataloader):\n",
    "\n",
    "        inputs  = inputs.to(device)\n",
    "        targets_golden = targets_golden.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            greedy_predictions = model.recognize(inputs, inputs_lengths)\n",
    "\n",
    "        # calculating Levenshtein Distance\n",
    "        # @NOTE: modify the print_example to print more or less validation examples\n",
    "        running_distance += calc_edit_distance(greedy_predictions, targets_golden, targets_lengths, tokenizer, print_example=True)\n",
    "\n",
    "        # online validation distance monitoring\n",
    "        batch_bar.set_postfix(\n",
    "            running_distance = \"{:.04f}\".format(float(running_distance / (i + 1)))\n",
    "        )\n",
    "\n",
    "        batch_bar.update()\n",
    "\n",
    "        del inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if i==4: break      # validating only upon first five batches\n",
    "\n",
    "    batch_bar.close()\n",
    "    running_distance /= 5\n",
    "\n",
    "    return running_distance\n",
    "\n",
    "def validate_full(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    # progress bar\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc=\"Val\", ncols=5)\n",
    "\n",
    "    running_distance = 0.0\n",
    "\n",
    "    for i, (inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths) in enumerate(dataloader):\n",
    "\n",
    "        inputs  = inputs.to(device)\n",
    "        targets_golden = targets_golden.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            greedy_predictions = model.recognize(inputs, inputs_lengths)\n",
    "\n",
    "        # calculating Levenshtein Distance\n",
    "        # @NOTE: modify the print_example to print more or less validation examples\n",
    "        running_distance += calc_edit_distance(greedy_predictions, targets_golden, targets_lengths, tokenizer, print_example=True)\n",
    "\n",
    "        # online validation distance monitoring\n",
    "        batch_bar.set_postfix(\n",
    "            running_distance = \"{:.04f}\".format(float(running_distance / (i + 1)))\n",
    "        )\n",
    "\n",
    "        batch_bar.update()\n",
    "\n",
    "        del inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    batch_bar.close()\n",
    "    running_distance /= len(dataloader)\n",
    "\n",
    "    return running_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_178601/3515402767.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler      = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "''' defining optimizer '''\n",
    "loss_func   = torch.nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)\n",
    "scaler      = torch.cuda.amp.GradScaler()\n",
    "if config[\"optimizer\"] == \"SGD\":\n",
    "  # feel free to change any of the initializations you like to fit your needs\n",
    "  optimizer = torch.optim.SGD(model.parameters(),\n",
    "                              lr=config[\"learning_rate\"],\n",
    "                              momentum=config[\"momentum\"],\n",
    "                              weight_decay=1E-4,\n",
    "                              nesterov=config[\"nesterov\"])\n",
    "\n",
    "elif config[\"optimizer\"] == \"Adam\":\n",
    "  # feel free to change any of the initializations you like to fit your needs\n",
    "  optimizer = torch.optim.Adam(model.parameters(),\n",
    "                               lr=float(config[\"learning_rate\"]),\n",
    "                               weight_decay=1e-4)\n",
    "\n",
    "elif config[\"optimizer\"] == \"AdamW\":\n",
    "  # feel free to change any of the initializations you like to fit your needs\n",
    "  optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                                lr=float(config[\"learning_rate\"]),\n",
    "                                weight_decay=0.01)\n",
    "\n",
    "''' defining scheduler '''\n",
    "\n",
    "if config[\"scheduler\"] == \"ReduceLR\":\n",
    "  #Feel Free to change any of the initializations you like to fit your needs\n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                factor=config[\"factor\"], patience=config[\"patience\"], min_lr=1E-8, verbose=True)\n",
    "\n",
    "elif config[\"scheduler\"] == \"CosineAnnealing\":\n",
    "  #Feel Free to change any of the initializations you like to fit your needs\n",
    "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                T_max = 35, eta_min=1E-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using WandB? resume training?\n",
    "\n",
    "USE_WANDB = False\n",
    "RESUME_LOGGING = False\n",
    "\n",
    "# creating your WandB run\n",
    "run_name = \"{}_Transformer_ENC-{}/{}_DEC-{}/{}_{}_{}_{}_{}\".format(\n",
    "    config[\"Name\"],\n",
    "    config[\"enc_num_layers\"],       # only used in Part II with the Transformer Encoder\n",
    "    config[\"enc_num_heads\"],        # only used in Part II with the Transformer Encoder\n",
    "    config[\"dec_num_layers\"],\n",
    "    config[\"dec_num_heads\"],\n",
    "    config[\"d_model\"],\n",
    "    config[\"d_ff\"],\n",
    "    config[\"optimizer\"],\n",
    "    config[\"scheduler\"])\n",
    "\n",
    "if USE_WANDB:\n",
    "\n",
    "    wandb.login(key=\"3c7b273814544590b64c54d9a5242bde38616e02\", relogin=True) # TODO enter your key here\n",
    "\n",
    "    if RESUME_LOGGING:\n",
    "        run_id = \"\"\n",
    "        run = wandb.init(\n",
    "            id     = run_id,        ### Insert specific run id here if you want to resume a previous run\n",
    "            resume = True,          ### You need this to resume previous runs, but comment out reinit=True when using this\n",
    "            project = \"HW4P2-S24\",  ### Project should be created in your wandb account\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        run = wandb.init(\n",
    "            name    = run_name,     ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
    "            reinit  = True,         ### Allows reinitalizing runs when you re-run this cell\n",
    "            project = \"HW4P2-S24\",  ### Project should be created in your wandb account\n",
    "            config  = config        ### Wandb Config for your run\n",
    "        )\n",
    "\n",
    "        ### Save your model architecture as a string with str(model)\n",
    "        model_arch  = str(model)\n",
    "\n",
    "        ### Save it in a txt file\n",
    "        arch_file   = open(\"model_arch.txt\", \"w\")\n",
    "        file_write  = arch_file.write(model_arch)\n",
    "        arch_file.close()\n",
    "\n",
    "        ### Log it in your wandb run with wandb.save()\n",
    "        # wandb.save(\"model_arch.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100: \n",
      "Train Loss 4.3791\t Train Perplexity 88.0941\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/100: \n",
      "Train Loss 4.2040\t Train Perplexity 66.9684\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/100: \n",
      "Train Loss 4.1866\t Train Perplexity 65.8153\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/100: \n",
      "Train Loss 4.1292\t Train Perplexity 62.2414\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/100: \n",
      "Train Loss 3.9200\t Train Perplexity 50.4634\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/100: \n",
      "Train Loss 3.8289\t Train Perplexity 46.0393\t Learning Rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 1/79 [00:17<22:16, 17.13s/it, running_distance=183.8438]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ቦታ ጥንት ዙሪያውን በውኃ የተከበበ ደሴት ነበር ይባላል::\n",
      "Prediction   :  በበ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 2/79 [00:25<15:27, 12.04s/it, running_distance=183.7578]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እንደማይመጣ ግልጽ ነው በወያኔዎች እንቶ ፈንቶ የዴሞክራሲ ልግጫ የኢትዮጵያ ኅልውና አይረጋገጥም ለውጥ የሚመጣው በጉልበት ነው በጣም በትንሽ ግን ጥበብ በተሞላበት\n",
      "Prediction   :  በበ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   4%|▍         | 3/79 [00:34<13:09, 10.38s/it, running_distance=183.7448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  በዚህም የሁለት ጊዜ ሻምፒዮኑ ኢትዮ ኤሌክትሪክ በዘጠኝ ነጥቦች መጨረሻ ደረጃ ላይ ተቀምጧል::\n",
      "Prediction   :  በበ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   5%|▌         | 4/79 [00:43<12:17,  9.83s/it, running_distance=183.9180]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ብነጻ ኣውጭ ስም በዘር የተደራጁ በሃይማኖት የተቁዋቁዋሙ ፓርቲዎችን በህግ ማፍረስ በህሳብ ኣይዲኦሎጂ በመሳሰሉት የተቁዋሙትን ማበረታታት::\n",
      "Prediction   :  በበ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   6%|▋         | 5/79 [00:51<11:41,  9.48s/it, running_distance=183.9750]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ምርቶችን የሚያከፋፍል ነው ለዚህ ኩባንያ በሽያጭ ሰራተኛነት ከመስራት አልፌ ፍራንቻይዝ ነኝ ምርቶቹን እኔ አከፋፍላለሁ በአጠቃላይ ግን በነዚህ ሰባትና ስምንት የሽያጭ\n",
      "Prediction   :  በበ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance 183.9750\n",
      "Saved best training model\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/100: \n",
      "Train Loss 3.7766\t Train Perplexity 43.6860\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/100: \n",
      "Train Loss 3.7504\t Train Perplexity 42.5633\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/100: \n",
      "Train Loss 3.7258\t Train Perplexity 41.5201\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100: \n",
      "Train Loss 3.7002\t Train Perplexity 40.4664\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/100: \n",
      "Train Loss 3.6732\t Train Perplexity 39.3909\t Learning Rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 1/79 [00:17<22:09, 17.04s/it, running_distance=155.1562]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ቦታ ጥንት ዙሪያውን በውኃ የተከበበ ደሴት ነበር ይባላል::\n",
      "Prediction   :  በን አን በመን በመን በት በመን በመን በት በመን በት በመን በት በት በት በት በት በት በት በት በመን በት በት በት በመን በት በመን በት በት በት በመን በት በመን በት በት በት በት በት በት በት በት በት በት በት በት በው:::ን በት በት በት በት በት በት በን በን በው በት በን በት በው በው በበበበበበበ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 2/79 [00:27<16:37, 12.96s/it, running_distance=157.9375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እንደማይመጣ ግልጽ ነው በወያኔዎች እንቶ ፈንቶ የዴሞክራሲ ልግጫ የኢትዮጵያ ኅልውና አይረጋገጥም ለውጥ የሚመጣው በጉልበት ነው በጣም በትንሽ ግን ጥበብ በተሞላበት\n",
      "Prediction   :  በን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በመ በት በመው በመን በት በት በመን በመን በት በት በት በው በት በት በት በት በመን በመን በው በው በው በት በመን በት በት በው በው በው በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   4%|▍         | 3/79 [00:35<13:51, 10.95s/it, running_distance=160.0833]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  በዚህም የሁለት ጊዜ ሻምፒዮኑ ኢትዮ ኤሌክትሪክ በዘጠኝ ነጥቦች መጨረሻ ደረጃ ላይ ተቀምጧል::\n",
      "Prediction   :  በን አን በመን በመን በት በት በመን በመን በት በት በመን በት በት በት በት በት በት በት በት በት በመን በት በት በመን በት በት በት በት በት በመን በት::ን:ን:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   5%|▌         | 4/79 [00:45<12:54, 10.33s/it, running_distance=159.7734]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ብነጻ ኣውጭ ስም በዘር የተደራጁ በሃይማኖት የተቁዋቁዋሙ ፓርቲዎችን በህግ ማፍረስ በህሳብ ኣይዲኦሎጂ በመሳሰሉት የተቁዋሙትን ማበረታታት::\n",
      "Prediction   :  በን በመን በመን በመን በመን በመን በመን በት በመን በት በመን በት በት በት በት በት በት በት በመን በመን በት በት በመን በት በመን በት በመን በት በት በት በመን በት በት በት በት በት በት በት በት በት በት በት በት በው በው በት በት በት በት በመን በመን በው በን በው በት በመን በት በው በው በበበበበበ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   6%|▋         | 5/79 [00:53<12:02,  9.76s/it, running_distance=158.3000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ምርቶችን የሚያከፋፍል ነው ለዚህ ኩባንያ በሽያጭ ሰራተኛነት ከመስራት አልፌ ፍራንቻይዝ ነኝ ምርቶቹን እኔ አከፋፍላለሁ በአጠቃላይ ግን በነዚህ ሰባትና ስምንት የሽያጭ\n",
      "Prediction   :  በን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በት በት በመን በመን በመን በመን በመን በመን በመ በመ በመን በመን በመን በመን በመን በመት በት በት በመን በት በት በት በት በት በት በት በት በው በው በት በት በት በመን በመን በው በን በው በት በመን በት በው በው በው በው በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance 158.3000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/100: \n",
      "Train Loss 3.6376\t Train Perplexity 38.0204\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/100: \n",
      "Train Loss 3.6054\t Train Perplexity 36.8119\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/100: \n",
      "Train Loss 3.5738\t Train Perplexity 35.6671\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/100: \n",
      "Train Loss 3.5515\t Train Perplexity 34.8819\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/100: \n",
      "Train Loss 3.5208\t Train Perplexity 33.8216\t Learning Rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 1/79 [00:17<22:37, 17.41s/it, running_distance=141.7344]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ቦታ ጥንት ዙሪያውን በውኃ የተከበበ ደሴት ነበር ይባላል::\n",
      "Prediction   :  የመ አን የመን ነው ነው:ል: ነው:::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 2/79 [00:26<16:09, 12.59s/it, running_distance=137.7266]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እንደማይመጣ ግልጽ ነው በወያኔዎች እንቶ ፈንቶ የዴሞክራሲ ልግጫ የኢትዮጵያ ኅልውና አይረጋገጥም ለውጥ የሚመጣው በጉልበት ነው በጣም በትንሽ ግን ጥበብ በተሞላበት\n",
      "Prediction   :  የመ የመን የመን የመን የመን የመመ የመመመ የመመ የመመመ የመመ የመመመ የመመመ የመመ የመመ የመመመ የመመ የመመመ የመመ የመመ የመመ የመመ የመመመ የመመመ የመመመመመ የመ የመመመ የት የመመመመመመመመመ የመመመመመ የመው የመመን የው የመን የመ የመ የመን የመን የመን የመን የመን የመን የመን የመን የመን የመን የየየ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   4%|▍         | 3/79 [00:34<13:14, 10.45s/it, running_distance=134.1562]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  በዚህም የሁለት ጊዜ ሻምፒዮኑ ኢትዮ ኤሌክትሪክ በዘጠኝ ነጥቦች መጨረሻ ደረጃ ላይ ተቀምጧል::\n",
      "Prediction   :  የመ አን የመን የመን የመን የመን የመን ነው ነው::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   5%|▌         | 4/79 [00:41<11:35,  9.27s/it, running_distance=134.1172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ብነጻ ኣውጭ ስም በዘር የተደራጁ በሃይማኖት የተቁዋቁዋሙ ፓርቲዎችን በህግ ማፍረስ በህሳብ ኣይዲኦሎጂ በመሳሰሉት የተቁዋሙትን ማበረታታት::\n",
      "Prediction   :  የመ የመን የመን የመን የመን የመን የመመን የመን የመን የመን የመን የመመመ የመመመ የመን የመመ የመመ የመመ የመስ የመ የመስ የመ የመ የመ የመመ የመመ የመመ የመመመ የመመመመ የት::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ምርቶችን የሚያከፋፍል ነው ለዚህ ኩባንያ በሽያጭ ሰራተኛነት ከመስራት አልፌ ፍራንቻይዝ ነኝ ምርቶቹን እኔ አከፋፍላለሁ በአጠቃላይ ግን በነዚህ ሰባትና ስምንት የሽያጭ\n",
      "Prediction   :  የመ የመን የመን የመን የመን የመመ የመመመ የመመ የመመመ የመመ የመመመ የመመመ የመመ የመመ የመመመ የመመመ የመመመ የመመመ የመመ የመመ የመመመ የመመመ የመመመ የመመመመ የመመመመ የት የመመመመመመመመመ የመመመመመ የመው የመመመን የው የመን የመ የመ የመ የመ የመን የመን የመን የመን የመን የመን የመን የመን የመን \n",
      "Levenshtein Distance 135.6906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best training model\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/100: \n",
      "Train Loss 3.5029\t Train Perplexity 33.2285\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/100: \n",
      "Train Loss 3.4843\t Train Perplexity 32.6111\t Learning Rate 0.0001\n",
      "Saved best training model\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/100: \n",
      "Train Loss 3.4637\t Train Perplexity 31.9491\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/100: \n",
      "Train Loss 3.4496\t Train Perplexity 31.5053\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/100: \n",
      "Train Loss 3.4337\t Train Perplexity 31.0052\t Learning Rate 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 1/79 [00:17<22:32, 17.34s/it, running_distance=150.2812]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ቦታ ጥንት ዙሪያውን በውኃ የተከበበ ደሴት ነበር ይባላል::\n",
      "Prediction   :  የመን አን አን አንደ አንደ አን አን አን ይ ይ ይ ይ ይ ይ ይ:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 2/79 [00:26<16:01, 12.49s/it, running_distance=147.4688]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እንደማይመጣ ግልጽ ነው በወያኔዎች እንቶ ፈንቶ የዴሞክራሲ ልግጫ የኢትዮጵያ ኅልውና አይረጋገጥም ለውጥ የሚመጣው በጉልበት ነው በጣም በትንሽ ግን ጥበብ በተሞላበት\n",
      "Prediction   :  በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመንግ በመን በመን በመን በመንግ በመንግ በመን በመን በመን በመን በመን የመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን የት የመን በመን በመን በመን የመን የመን የመን በመን የየየየየየየየየየየየየአን በየ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   4%|▍         | 3/79 [00:35<13:49, 10.91s/it, running_distance=145.6250]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  በዚህም የሁለት ጊዜ ሻምፒዮኑ ኢትዮ ኤሌክትሪክ በዘጠኝ ነጥቦች መጨረሻ ደረጃ ላይ ተቀምጧል::\n",
      "Prediction   :  የመን የተን የተመን የተመስ የተመስ የመን የተመስ የተገስ የተገ የተገ የመስ የመስ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   5%|▌         | 4/79 [00:44<12:34, 10.06s/it, running_distance=145.4805]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ብነጻ ኣውጭ ስም በዘር የተደራጁ በሃይማኖት የተቁዋቁዋሙ ፓርቲዎችን በህግ ማፍረስ በህሳብ ኣይዲኦሎጂ በመሳሰሉት የተቁዋሙትን ማበረታታት::\n",
      "Prediction   :  በመን የመን የመን የተመን የተመን የመን የመን የተመን የተመስ የተመን የተመስ የተመስ የተመን የተመስ የመስ የመስ የተስ የመስ የመስ የመስ የመስ የመስ የመን የመን የመንልልልልል::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   6%|▋         | 5/79 [00:52<11:41,  9.47s/it, running_distance=147.4156]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ምርቶችን የሚያከፋፍል ነው ለዚህ ኩባንያ በሽያጭ ሰራተኛነት ከመስራት አልፌ ፍራንቻይዝ ነኝ ምርቶቹን እኔ አከፋፍላለሁ በአጠቃላይ ግን በነዚህ ሰባትና ስምንት የሽያጭ\n",
      "Prediction   :  በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመን በመንግ በመን በመንግ በመን በመንግ በመንግ በመን በመንግን በመንግን በመን በመን በመን በመን በመን በመንግን በመን በመን በመን በመን በመን በመን በት በመን በመን በመን በመን በመን የመን በመን በመን በየየየየየየየየየየየየየአንግን \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance 147.4156\n",
      "Saved best training model\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/100: \n",
      "Train Loss 3.4203\t Train Perplexity 30.5909\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/100: \n",
      "Train Loss 3.4098\t Train Perplexity 30.2773\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/100: \n",
      "Train Loss 3.4021\t Train Perplexity 30.0356\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/100: \n",
      "Train Loss 3.3902\t Train Perplexity 29.6873\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/100: \n",
      "Train Loss 3.3827\t Train Perplexity 29.4627\t Learning Rate 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 1/79 [00:12<16:35, 12.76s/it, running_distance=140.6875]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ቦታ ጥንት ዙሪያውን በውኃ የተከበበ ደሴት ነበር ይባላል::\n",
      "Prediction   :  የመን የተመን የተመስ የተመስ የተመ የተመስ የተገ ነው:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 2/79 [00:20<12:17,  9.58s/it, running_distance=134.7188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እንደማይመጣ ግልጽ ነው በወያኔዎች እንቶ ፈንቶ የዴሞክራሲ ልግጫ የኢትዮጵያ ኅልውና አይረጋገጥም ለውጥ የሚመጣው በጉልበት ነው በጣም በትንሽ ግን ጥበብ በተሞላበት\n",
      "Prediction   :  በመን የመን የመን የተመስ የመን የመን የመን የመን የመንግ የተመን የተመስ የተመን የተመን የተመስ የተመስ የተመን የተመስ የተመስ የተመስ የተመስ የተመስ የተስ የተመን የተመስውንንንንንንንንንንንን\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   4%|▍         | 3/79 [00:28<11:09,  8.81s/it, running_distance=134.2031]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  በዚህም የሁለት ጊዜ ሻምፒዮኑ ኢትዮ ኤሌክትሪክ በዘጠኝ ነጥቦች መጨረሻ ደረጃ ላይ ተቀምጧል::\n",
      "Prediction   :  የመን የተመን የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የመስ ነ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   5%|▌         | 4/79 [00:34<09:56,  7.96s/it, running_distance=135.1289]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ብነጻ ኣውጭ ስም በዘር የተደራጁ በሃይማኖት የተቁዋቁዋሙ ፓርቲዎችን በህግ ማፍረስ በህሳብ ኣይዲኦሎጂ በመሳሰሉት የተቁዋሙትን ማበረታታት::\n",
      "Prediction   :  በመን የመን የመን የተመስ የተመን የመን የተመስ የተመስ የተመስ የተመስ የተመስ የመን የተመን የተመስ የተመስ የተመስ የተመስ የተስ የተስ የተመስ የተስል:::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ምርቶችን የሚያከፋፍል ነው ለዚህ ኩባንያ በሽያጭ ሰራተኛነት ከመስራት አልፌ ፍራንቻይዝ ነኝ ምርቶቹን እኔ አከፋፍላለሁ በአጠቃላይ ግን በነዚህ ሰባትና ስምንት የሽያጭ\n",
      "Prediction   :  በመን የመን የመን የመን የመን የመን የመን የመን የተመን የተመስ የተመስ የመንግ የተመን የተመን የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመን የተመን የተመን የትንንንንንንንትንንትትንንትትንንንን የትን የትን የሚን የሚንንን የየየየየየየየየየየየየየየየየየየየየየየ\n",
      "Levenshtein Distance 136.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best training model\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/100: \n",
      "Train Loss 3.3782\t Train Perplexity 29.3316\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/100: \n",
      "Train Loss 3.3732\t Train Perplexity 29.1867\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/100: \n",
      "Train Loss 3.3652\t Train Perplexity 28.9554\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/100: \n",
      "Train Loss 3.3660\t Train Perplexity 28.9757\t Learning Rate 0.0000\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/100: \n",
      "Train Loss 3.3603\t Train Perplexity 28.8105\t Learning Rate 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 1/79 [00:09<12:23,  9.53s/it, running_distance=136.5938]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ቦታ ጥንት ዙሪያውን በውኃ የተከበበ ደሴት ነበር ይባላል::\n",
      "Prediction   :  የመን የተመስ የተመስ የተመስ የተመ የመን የመለው:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 2/79 [00:16<10:07,  7.89s/it, running_distance=131.6250]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እንደማይመጣ ግልጽ ነው በወያኔዎች እንቶ ፈንቶ የዴሞክራሲ ልግጫ የኢትዮጵያ ኅልውና አይረጋገጥም ለውጥ የሚመጣው በጉልበት ነው በጣም በትንሽ ግን ጥበብ በተሞላበት\n",
      "Prediction   :  በመለው የተመስ የተመስ የመንግ የመንግ የመንግ የተመስ የመንግ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተስ የተስ የተመስ የመንግ የመን የተስንንንንንንንን\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   4%|▍         | 3/79 [00:23<09:23,  7.41s/it, running_distance=131.6354]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  በዚህም የሁለት ጊዜ ሻምፒዮኑ ኢትዮ ኤሌክትሪክ በዘጠኝ ነጥቦች መጨረሻ ደረጃ ላይ ተቀምጧል::\n",
      "Prediction   :  የመን የተመስ የተመስ የመን የተመስ የመን የመን የተመስ የመን የተመስ ነው:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   5%|▌         | 4/79 [00:30<09:02,  7.23s/it, running_distance=131.9727]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ብነጻ ኣውጭ ስም በዘር የተደራጁ በሃይማኖት የተቁዋቁዋሙ ፓርቲዎችን በህግ ማፍረስ በህሳብ ኣይዲኦሎጂ በመሳሰሉት የተቁዋሙትን ማበረታታት::\n",
      "Prediction   :  የመን የመን የመንግ የመንግ የመንግ የመን የመንግ የተመስ የተመስ የተመስ የመንግ የመንግ የተመስ የተስ የመስ የመስ የተስ የተስ የተስ የተስ የመስል:::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ምርቶችን የሚያከፋፍል ነው ለዚህ ኩባንያ በሽያጭ ሰራተኛነት ከመስራት አልፌ ፍራንቻይዝ ነኝ ምርቶቹን እኔ አከፋፍላለሁ በአጠቃላይ ግን በነዚህ ሰባትና ስምንት የሽያጭ\n",
      "Prediction   :  በመን የመን የመንግ የመንግ የመንግ የመን የመንግ የተመስ የተመስ የተመስ የመንግ የመንግ የተመስ የተመስ የመንግ የተመስ የተስ የተመስ የተመስ የመንግስ የመንግን የተመን የተመስርንንንን የትንንንንንንንንንንንን\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance 132.7344\n",
      "Saved best training model\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/100: \n",
      "Train Loss 3.3584\t Train Perplexity 28.7577\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/100: \n",
      "Train Loss 3.3580\t Train Perplexity 28.7480\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/100: \n",
      "Train Loss 3.3563\t Train Perplexity 28.6986\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/100: \n",
      "Train Loss 3.3565\t Train Perplexity 28.7009\t Learning Rate 0.0000\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/100: \n",
      "Train Loss 3.3543\t Train Perplexity 28.6397\t Learning Rate 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 1/79 [00:10<13:42, 10.55s/it, running_distance=139.0312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ቦታ ጥንት ዙሪያውን በውኃ የተከበበ ደሴት ነበር ይባላል::\n",
      "Prediction   :  የመን የተመስ የተመስ የተመስ የተመ የመን የመስ ነው::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 2/79 [00:17<10:44,  8.36s/it, running_distance=134.1016]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እንደማይመጣ ግልጽ ነው በወያኔዎች እንቶ ፈንቶ የዴሞክራሲ ልግጫ የኢትዮጵያ ኅልውና አይረጋገጥም ለውጥ የሚመጣው በጉልበት ነው በጣም በትንሽ ግን ጥበብ በተሞላበት\n",
      "Prediction   :  የአን የመን የመንግ የመንግ የመንግ የመንግ የመን የተመስ የመንግ የመንግ የመንግ የመንግ የተመስ የተመስ የመንግ የተመስ የተስ የተመስ የተመስ የመንግ የመንግን የተስልንንንንንንንንን የየየየየየየየ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   4%|▍         | 3/79 [00:24<09:35,  7.57s/it, running_distance=134.3073]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  በዚህም የሁለት ጊዜ ሻምፒዮኑ ኢትዮ ኤሌክትሪክ በዘጠኝ ነጥቦች መጨረሻ ደረጃ ላይ ተቀምጧል::\n",
      "Prediction   :  የአን የመን የተመስ የተመስ የተመስ የመን የመን የተመስ የመን የተመስ የመል:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   5%|▌         | 4/79 [00:30<09:09,  7.32s/it, running_distance=134.5000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ብነጻ ኣውጭ ስም በዘር የተደራጁ በሃይማኖት የተቁዋቁዋሙ ፓርቲዎችን በህግ ማፍረስ በህሳብ ኣይዲኦሎጂ በመሳሰሉት የተቁዋሙትን ማበረታታት::\n",
      "Prediction   :  የአን የመን የመንግ የመንግ የመንግ የመን የመንግ የተመስ የተመስ የተመስ የመንግ የመንግ የተመስ የመን የመን የመን የተስ አስ አስ አስ አስ:::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ምርቶችን የሚያከፋፍል ነው ለዚህ ኩባንያ በሽያጭ ሰራተኛነት ከመስራት አልፌ ፍራንቻይዝ ነኝ ምርቶቹን እኔ አከፋፍላለሁ በአጠቃላይ ግን በነዚህ ሰባትና ስምንት የሽያጭ\n",
      "Prediction   :  የአን የመን የመንግ የመንግ የመንግ የመንግ የመን የመንግ የመንግ የመንግ የመንግ የመንግ የተመስ የተመስ የመንግ የተመስ የተመስ የተመስ የተመስ የመንግን የመንግን የመንግን የመን የትንንንንንንትንንትትንንትትንንንንንንንን የአንንንንንንንንንንንንንንንንንን\n",
      "Levenshtein Distance 135.7656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best training model\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/100: \n",
      "Train Loss 3.3540\t Train Perplexity 28.6311\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/100: \n",
      "Train Loss 3.3565\t Train Perplexity 28.7020\t Learning Rate 0.0000\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/100: \n",
      "Train Loss 3.3533\t Train Perplexity 28.6106\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/100: \n",
      "Train Loss 3.3574\t Train Perplexity 28.7290\t Learning Rate 0.0000\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41/100: \n",
      "Train Loss 3.3554\t Train Perplexity 28.6679\t Learning Rate 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 1/79 [00:09<11:54,  9.16s/it, running_distance=138.7031]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ቦታ ጥንት ዙሪያውን በውኃ የተከበበ ደሴት ነበር ይባላል::\n",
      "Prediction   :  የመን የተመስ የተመስ የተመስ የተመስ የተመስ የመለው::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 2/79 [00:16<10:11,  7.94s/it, running_distance=134.6094]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እንደማይመጣ ግልጽ ነው በወያኔዎች እንቶ ፈንቶ የዴሞክራሲ ልግጫ የኢትዮጵያ ኅልውና አይረጋገጥም ለውጥ የሚመጣው በጉልበት ነው በጣም በትንሽ ግን ጥበብ በተሞላበት\n",
      "Prediction   :  የአለው የተመን የተመስ የተመን የመንግ የተመስ የተመን የተመስ የተመስ የተመስ የተመስ የተመን የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተስን የት የትን የት የትን የት የተን የት የት የት የት የየየየየየየየየየየየየየየየየየየየየ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   4%|▍         | 3/79 [00:23<09:36,  7.58s/it, running_distance=134.4167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  በዚህም የሁለት ጊዜ ሻምፒዮኑ ኢትዮ ኤሌክትሪክ በዘጠኝ ነጥቦች መጨረሻ ደረጃ ላይ ተቀምጧል::\n",
      "Prediction   :  የመን የመን የተመስ የተመስ የተመስ የመን የመን የተመስ የተመስ የመን አይ:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   5%|▌         | 4/79 [00:30<09:18,  7.45s/it, running_distance=134.6836]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ብነጻ ኣውጭ ስም በዘር የተደራጁ በሃይማኖት የተቁዋቁዋሙ ፓርቲዎችን በህግ ማፍረስ በህሳብ ኣይዲኦሎጂ በመሳሰሉት የተቁዋሙትን ማበረታታት::\n",
      "Prediction   :  የአን የመን የመንግ የመንግ የመንግ የመን የመንግ የተመስ የተመስ የተመስ የመንግ የመንግ የተመስ የተስ የመን የመን የተስ የተስ አስ አስ አስ::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ምርቶችን የሚያከፋፍል ነው ለዚህ ኩባንያ በሽያጭ ሰራተኛነት ከመስራት አልፌ ፍራንቻይዝ ነኝ ምርቶቹን እኔ አከፋፍላለሁ በአጠቃላይ ግን በነዚህ ሰባትና ስምንት የሽያጭ\n",
      "Prediction   :  በመለው የተመን የተመስ የመንግ የመንግ የተመስ የተመስ የመንግ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስርስን የትን የት የትን የትን የየየየየየየየየየየየየየየየየየየየ\n",
      "Levenshtein Distance 135.7937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/100: \n",
      "Train Loss 3.3515\t Train Perplexity 28.5584\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43/100: \n",
      "Train Loss 3.3519\t Train Perplexity 28.5754\t Learning Rate 0.0000\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/100: \n",
      "Train Loss 3.3512\t Train Perplexity 28.5508\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/100: \n",
      "Train Loss 3.3458\t Train Perplexity 28.3970\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/100: \n",
      "Train Loss 3.3445\t Train Perplexity 28.3579\t Learning Rate 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 1/79 [00:09<11:59,  9.23s/it, running_distance=143.1250]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ቦታ ጥንት ዙሪያውን በውኃ የተከበበ ደሴት ነበር ይባላል::\n",
      "Prediction   :  የአን የተመን የተመስ የተስ የተመ የመን የመን የተለው:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 2/79 [00:12<07:40,  5.98s/it, running_distance=116.7500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እንደማይመጣ ግልጽ ነው በወያኔዎች እንቶ ፈንቶ የዴሞክራሲ ልግጫ የኢትዮጵያ ኅልውና አይረጋገጥም ለውጥ የሚመጣው በጉልበት ነው በጣም በትንሽ ግን ጥበብ በተሞላበት\n",
      "Prediction   :  የአን የተመን የተመስ የመንግ የተመስ የተመስ የተመስ የመንግ የተመስ የመንግ የተመስ የተመስ የተመስ የተመስ የተመስ የተመስ የተስ የመንግ የተመስ የመንግ የመንግን የመን\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   4%|▍         | 3/79 [00:19<08:06,  6.40s/it, running_distance=124.6354]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  በዚህም የሁለት ጊዜ ሻምፒዮኑ ኢትዮ ኤሌክትሪክ በዘጠኝ ነጥቦች መጨረሻ ደረጃ ላይ ተቀምጧል::\n",
      "Prediction   :  የአን የመን የተመስ የመን የመን የመን የመን የመን የመንግ የተመን የመን ነው::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   5%|▌         | 4/79 [00:26<08:19,  6.65s/it, running_distance=128.5703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ብነጻ ኣውጭ ስም በዘር የተደራጁ በሃይማኖት የተቁዋቁዋሙ ፓርቲዎችን በህግ ማፍረስ በህሳብ ኣይዲኦሎጂ በመሳሰሉት የተቁዋሙትን ማበረታታት::\n",
      "Prediction   :  የአን የመን የመንግ የመንግ የመን የመን የመን የተመን የመንግ የተመስ የመንግ የመንግ የተመን የመን የመን የመን አስ አስ አስ አስ አስ አስል::ል::ል::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ምርቶችን የሚያከፋፍል ነው ለዚህ ኩባንያ በሽያጭ ሰራተኛነት ከመስራት አልፌ ፍራንቻይዝ ነኝ ምርቶቹን እኔ አከፋፍላለሁ በአጠቃላይ ግን በነዚህ ሰባትና ስምንት የሽያጭ\n",
      "Prediction   :  የአንግ የተመን የተመስ የመንግ የመን የመንግ የመንግ የመንግ የተመስ የመንግ የተመስ የተመን የተመስ የተመስ የመንግ የተመስ የመንግ የተመስ የተመስ የተመንግ የተስት የተመንግንግንንንንንትትንንንን የትን የትን የሚን የትንን የትን የየየየየየየየየየየየየየየየየየየ\n",
      "Levenshtein Distance 131.2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best training model\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/100: \n",
      "Train Loss 3.3390\t Train Perplexity 28.2065\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48/100: \n",
      "Train Loss 3.3333\t Train Perplexity 28.0408\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49/100: \n",
      "Train Loss 3.3295\t Train Perplexity 27.9465\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/100: \n",
      "Train Loss 3.3213\t Train Perplexity 27.7101\t Learning Rate 0.0000\n",
      "Saved best training model\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_178601/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Train:  86%|████████▌ | 68/79 [01:24<00:12,  1.18s/it, loss=3.3125, perplexity=27.4689]"
     ]
    }
   ],
   "source": [
    "e                   = 0\n",
    "best_loss           = 20\n",
    "\n",
    "checkpoint_root = os.path.join(os.getcwd(), \"checkpoints-basic-transformer\")\n",
    "os.makedirs(checkpoint_root, exist_ok=True)\n",
    "if USE_WANDB:\n",
    "    wandb.watch(model, log=\"all\")\n",
    "\n",
    "checkpoint_best_loss_model_filename     = 'checkpoint-best-loss-model.pth'\n",
    "checkpoint_last_epoch_filename          = 'checkpoint-epoch-'\n",
    "best_loss_model_path                    = os.path.join(checkpoint_root, checkpoint_best_loss_model_filename)\n",
    "\n",
    "if RESUME_LOGGING:\n",
    "    # change if you want to load best test model accordingly\n",
    "    checkpoint = torch.load(wandb.restore(checkpoint_best_loss_model_filename, run_path=\"\"+run_id).name)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    e = checkpoint['epoch']\n",
    "\n",
    "    print(\"Resuming from epoch {}\".format(e+1))\n",
    "    print(\"Epochs left: \", config['epochs']-e)\n",
    "    print(\"Optimizer: \\n\", optimizer)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "epochs = config[\"epochs\"]\n",
    "for epoch in range(e, epochs):\n",
    "\n",
    "    print(\"\\nEpoch {}/{}\".format(epoch+1, config[\"epochs\"]))\n",
    "\n",
    "    curr_lr = float(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    train_loss, train_perplexity, attention_weights = train_model(model, train_loader, optimizer)\n",
    "\n",
    "    print(\"\\nEpoch {}/{}: \\nTrain Loss {:.04f}\\t Train Perplexity {:.04f}\\t Learning Rate {:.04f}\".format(\n",
    "        epoch + 1, config[\"epochs\"], train_loss, train_perplexity, curr_lr))\n",
    "\n",
    "    if (epoch >0 )and (epoch % 5 == 0):    # validate every 2 epochs to speed up training\n",
    "        levenshtein_distance = validate_fast(model, val_loader)\n",
    "        print(\"Levenshtein Distance {:.04f}\".format(levenshtein_distance))\n",
    "        if USE_WANDB:\n",
    "            wandb.log({\"train_loss\"     : train_loss,\n",
    "                    \"train_perplexity\"  : train_perplexity,\n",
    "                    \"learning_rate\"     : curr_lr,\n",
    "                    \"val_distance\"      : levenshtein_distance})\n",
    "\n",
    "    else:\n",
    "        if USE_WANDB:\n",
    "\n",
    "            wandb.log({\"train_loss\"     : train_loss,\n",
    "                    \"train_perplexity\"  : train_perplexity,\n",
    "                    \"learning_rate\"     : curr_lr})\n",
    "\n",
    "    # plotting the encoder-nearest and decoder-nearest attention weights\n",
    "    attention_keys = list(attention_weights.keys())\n",
    "\n",
    "    attention_weights_decoder_self       = attention_weights[attention_keys[0]][0].cpu().detach().numpy()\n",
    "    attention_weights_decoder_cross      = attention_weights[attention_keys[-1]][0].cpu().detach().numpy()\n",
    "\n",
    "    # saving the cross-attention weights\n",
    "    save_attention_plot(attention_weights_decoder_cross, epoch+100)\n",
    "\n",
    "    # plot_attention_weights((attention_weights[attention_keys[0]][0]).cpu().detach().numpy())\n",
    "    # plot_attention_weights(attention_weights[attention_keys[-1]][0].cpu().detach().numpy())\n",
    "\n",
    "    if config[\"scheduler\"] == \"ReduceLR\":\n",
    "        scheduler.step(levenshtein_distance)\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    # ### Highly Recommended: Save checkpoint in drive and/or wandb if accuracy is better than your current best\n",
    "    # epoch_model_path = os.path.join(checkpoint_root, (checkpoint_last_epoch_filename + str(epoch) + '.pth'))\n",
    "    # save_model(model, optimizer, scheduler, ['train_loss', train_loss], epoch, epoch_model_path)\n",
    "    ## wandb.save(epoch_model_path) ## Can't save on wandb for all epochs, may blow up storage\n",
    "\n",
    "\n",
    "    if best_loss >= train_loss:\n",
    "        best_loss = train_loss\n",
    "        save_model(model, optimizer, scheduler, ['train_loss', train_loss], epoch, best_loss_model_path)\n",
    "        # wandb.save(best_loss_model_path)\n",
    "        print(\"Saved best training model\")\n",
    "\n",
    "### Finish your wandb run\n",
    "# run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
