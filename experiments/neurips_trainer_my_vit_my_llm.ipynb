{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/datagen/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config {'SCENARIO': 1, 'USE_WANDB': True, 'TRAIN_TASK': 'SYNTHETIC', 'HANDWRITTEN_TRAIN_PATH': '/home/ubuntu/data/handwritten_labels/train.csv', 'HANDWRITTEN_VAL_PATH': '/home/ubuntu/data/handwritten_labels/test.csv', 'HANDWRITTEN_IMG_ROOT': '/home/ubuntu/data/handwritten_data', 'TYPED_TRAIN_PATH': '/home/ubuntu/data/typed_labels/train.csv', 'TYPED_VAL_PATH': '/home/ubuntu/data/typed_labels/test.csv', 'TYPED_IMG_ROOT': '/home/ubuntu/data/typed_data', 'SYNTHETIC_TRAIN_PATH': '/home/ubuntu/data/synthetic_data/labels/output_labels_train.csv', 'SYNTHETIC_VAL_PATH': '/home/ubuntu/data/synthetic_data/labels/output_labels_test.csv', 'SYNTHETIC_IMG_ROOT': '/home/ubuntu/data/synthetic_data/data', 'BATCH_SIZE': 64, 'MODEL_ID': 'microsoft/trocr-base-handwritten', 'EPOCHS': 100, 'enc_dropout': 0.2, 'enc_num_layers': 1, 'enc_num_heads': 1, 'dec_dropout': 0.2, 'dec_num_layers': 6, 'dec_num_heads': 8, 'd_model': 256, 'd_ff': 1024, 'learning_rate': '5E-5', 'optimizer': 'AdamW', 'momentum': 0.0, 'nesterov': True, 'scheduler': 'CosineAnnealing', 'factor': 0.9, 'patience': 6, 'epochs': 50, 'Name': 'blessed', 'BEAM_WIDTH': 10}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataset.dataloader import MyOcrDataloader, MyCustomOcrDataloader, OCRDataAugmentor\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import yaml\n",
    "import wandb\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import gc\n",
    "from utils.utils import *\n",
    "from utils.charactertokenizer import CharacterTokenizer\n",
    "from jiwer import wer, cer\n",
    "from models.models import TrOCRMyDecoder\n",
    "from models.vit import ViT\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = ViT(image_size = (256, 1024), num_classes= None, mlp_dim=1024, patch_size=32, dim=512, depth= 4, heads = 4 )\n",
    "# img = torch.randn(1, 3, 256, 1024)\n",
    "\n",
    "# preds = encoder(img) # (1, 1000)\n",
    "# preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), '..')), \"config/main.yaml\")\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "task  = config[\"TRAIN_TASK\"]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "TRAIN_PATH =config[task+\"_\"+\"TRAIN_PATH\"]\n",
    "VAL_PATH =config[task+\"_\"+\"VAL_PATH\"]\n",
    "IMG_ROOT = config[task+\"_\"+\"IMG_ROOT\"]\n",
    "\n",
    "MODEL_ID = config[\"MODEL_ID\"]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = resize_and_patch_image\n",
    "# model =VisionEncoderDecoderModel.from_pretrained(MODEL_ID).to(device)\n",
    "# model.config.decoder_start_token_id = processor.tokenizer.eos_token_id\n",
    "# model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "# model.config.vocab_size = model.config.decoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"rasyosef/bert-amharic-tokenizer\")\n",
    "# tokenizer.tokenize(\"የዓለምአቀፉ ነጻ ንግድ መስፋፋት ድህነትን ለማሸነፍ በሚደረገው ትግል አንዱ ጠቃሚ መሣሪያ ሊሆን መቻሉ ብዙ የሚነገርለት ጉዳይ ነው።\")\n",
    "# tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting tokenizer\n"
     ]
    }
   ],
   "source": [
    "## sanity check for data loader\n",
    "os.chdir(\"../dataset\")\n",
    "augmentor = OCRDataAugmentor()\n",
    "# tokenizer = CharacterTokenizer.from_pretrained('/home/ubuntu/HandWritten_Amharic_English_OCR/Amharic_Char_Tokenizer2')\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"/home/ubuntu/data/synthetic_data/amharic_tokenizer_hf\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"rasyosef/bert-amharic-tokenizer\")\n",
    "\n",
    "if tokenizer.bos_token_id== None:\n",
    "    print(\"setting tokenizer\")\n",
    "    special_tokens_dict = {\n",
    "    \"bos_token\": \"<sos>\",\n",
    "    \"eos_token\": \"<eos>\"\n",
    "    }\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "train_data = MyCustomOcrDataloader(TRAIN_PATH, preprocessor=processor, tokenizer  = tokenizer, img_root=IMG_ROOT, transform=augmentor)\n",
    "val_data = MyCustomOcrDataloader(VAL_PATH, preprocessor=processor, tokenizer  = tokenizer, img_root=IMG_ROOT)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = train_data,\n",
    "    batch_size  = config['BATCH_SIZE'],\n",
    "    shuffle     = True,\n",
    "    collate_fn= train_data.collate_fn\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Train Images   :  10000\n",
      "Batch Size           :  64\n",
      "Train Batches        :  157\n",
      "Val Batches          :  157\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader    = torch.utils.data.DataLoader(\n",
    "    dataset     = train_data,\n",
    "    batch_size  = config[\"BATCH_SIZE\"],\n",
    "    shuffle     = True,\n",
    "    num_workers = 4,\n",
    "    pin_memory  = True,\n",
    "    collate_fn  = train_data.collate_fn\n",
    ")\n",
    "\n",
    "val_loader      = torch.utils.data.DataLoader(\n",
    "    dataset     = val_data,\n",
    "    batch_size  = config[\"BATCH_SIZE\"],\n",
    "    shuffle     = False,\n",
    "    num_workers = 2,\n",
    "    pin_memory  = True,\n",
    "    collate_fn  = train_data.collate_fn,\n",
    ")\n",
    "\n",
    "print(\"No. of Train Images   : \", train_data.__len__())\n",
    "print(\"Batch Size           : \", config[\"BATCH_SIZE\"])\n",
    "print(\"Train Batches        : \", train_loader.__len__())\n",
    "print(\"Val Batches          : \", val_loader.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Shapes of the Data --\n",
      "\n",
      "x_pad shape:\t\ttorch.Size([64, 1, 3, 256, 1024])\n",
      "x_len shape:\t\ttorch.Size([64])\n",
      "\n",
      "y_shifted_pad shape:\ttorch.Size([64, 33])\n",
      "y_golden_pad shape:\ttorch.Size([64, 33])\n",
      "y_len shape:\t\ttorch.Size([64])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Sanity Check '''\n",
    "\n",
    "print(\"Checking the Shapes of the Data --\\n\")\n",
    "\n",
    "for batch in train_loader:\n",
    "    x_pad, y_shifted_pad, y_golden_pad, x_len, y_len, = batch\n",
    "\n",
    "    print(f\"x_pad shape:\\t\\t{x_pad.shape}\")\n",
    "    print(f\"x_len shape:\\t\\t{x_len.shape}\\n\")\n",
    "\n",
    "    print(f\"y_shifted_pad shape:\\t{y_shifted_pad.shape}\")\n",
    "    print(f\"y_golden_pad shape:\\t{y_golden_pad.shape}\")\n",
    "    print(f\"y_len shape:\\t\\t{y_len.shape}\\n\")\n",
    "    plt.imshow(x_pad[0][0].permute((1,2,0)))\n",
    "    # print(y_shifted_pad)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Model Parameters:\n",
      " 30.89101\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "''' Please refer to the config file and top sections to fill in the following '''\n",
    "\n",
    "model = TrOCRMyDecoder(\n",
    "input_dim                   = None,\n",
    "dec_num_layers              = config[\"dec_num_layers\"],\n",
    "dec_num_heads               = config[\"dec_num_heads\"],\n",
    "\n",
    "d_model                     = config[\"d_model\"],\n",
    "d_ff                        = config[\"d_ff\"],\n",
    "\n",
    "target_vocab_size           = len(tokenizer),\n",
    "eos_token                   = tokenizer.eos_token_id,\n",
    "sos_token                   = tokenizer.bos_token_id,\n",
    "pad_token                   = tokenizer.pad_token_id,\n",
    "\n",
    "enc_dropout                 = config[\"enc_dropout\"],\n",
    "dec_dropout                 = config[\"enc_dropout\"],\n",
    "\n",
    "# decrease to a small number if you are just trying to implement the network\n",
    "max_seq_length              = 512 , # Max sequence length for transcripts. Check data verification.\n",
    ").to(device)\n",
    "\n",
    "def num_parameters(mode):\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params / 1E6\n",
    "\n",
    "para = num_parameters(model)\n",
    "print(\"#\"*10)\n",
    "print(f\"Model Parameters:\\n {para}\")\n",
    "print(\"#\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc=\"Train\")\n",
    "\n",
    "    total_loss          = 0\n",
    "    running_loss        = 0.0\n",
    "    running_perplexity  = 0.0\n",
    "\n",
    "    for i, (inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs          = inputs.to(device)\n",
    "        targets_shifted = targets_shifted.to(device)\n",
    "        targets_golden  = targets_golden.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # passing the minibatch through the model\n",
    "            # raw_predictions, attention_weights = model(inputs, inputs_lengths, targets_shifted, targets_lengths)\n",
    "            raw_predictions, attention_weights = model(inputs, inputs_lengths, targets_shifted, targets_lengths)\n",
    "\n",
    "\n",
    "            padding_mask = torch.logical_not(torch.eq(targets_shifted, tokenizer.pad_token_id))\n",
    "\n",
    "            # cast the mask to float32\n",
    "            padding_mask = padding_mask.float()\n",
    "            loss = loss_func(raw_predictions.transpose(1,2), targets_golden)*padding_mask\n",
    "            loss = loss.sum() / padding_mask.sum()\n",
    "\n",
    "        scaler.scale(loss).backward()   # This is a replacement for loss.backward()\n",
    "        scaler.step(optimizer)          # This is a replacement for optimizer.step()\n",
    "        scaler.update()                 # This is something added just for FP16\n",
    "\n",
    "        running_loss        += float(loss.item())\n",
    "        perplexity          = torch.exp(loss)\n",
    "        running_perplexity  += perplexity.item()\n",
    "\n",
    "        # online training monitoring\n",
    "        batch_bar.set_postfix(\n",
    "            loss = \"{:.04f}\".format(float(running_loss / (i + 1))),\n",
    "            perplexity = \"{:.04f}\".format(float(running_perplexity / (i + 1)))\n",
    "        )\n",
    "\n",
    "        batch_bar.update()\n",
    "\n",
    "        del inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    running_loss        = float(running_loss / len(train_loader))\n",
    "    running_perplexity  = float(running_perplexity / len(train_loader))\n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    return running_loss, running_perplexity, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_fast(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    # progress bar\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc=\"Val\", ncols=5)\n",
    "\n",
    "    running_distance = 0.0\n",
    "    running_cer = 0.0\n",
    "    running_wer = 0.0\n",
    "    running_char_f1 = 0.0\n",
    "    running_word_f1 = 0.0\n",
    "\n",
    "\n",
    "    for i, (inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths) in enumerate(dataloader):\n",
    "\n",
    "        inputs  = inputs.to(device)\n",
    "        targets_golden = targets_golden.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            greedy_predictions = model.recognize(inputs, inputs_lengths)\n",
    "\n",
    "        # calculating Levenshtein Distance\n",
    "        # @NOTE: modify the print_example to print more or less validation examples\n",
    "        dist, cer, wer, charf1, word_f1 = calc_edit_distance(greedy_predictions, targets_golden, targets_lengths, tokenizer, print_example=True)\n",
    "        running_distance += dist\n",
    "        running_cer += cer\n",
    "        running_wer += wer\n",
    "        running_char_f1 += charf1\n",
    "        running_word_f1 += word_f1\n",
    "\n",
    "\n",
    "        # online validation distance monitoring\n",
    "        batch_bar.set_postfix(\n",
    "            running_distance = \"{:.04f}\".format(float(running_distance / (i + 1))),\n",
    "            running_cer = \"{:.04f}\".format(float(running_cer / (i + 1))),\n",
    "            running_wer = \"{:.04f}\".format(float(running_wer / (i + 1))),\n",
    "            running_char_f1 = \"{:.04f}\".format(float(running_char_f1 / (i + 1))),\n",
    "            running_word_f1 = \"{:.04f}\".format(float(running_word_f1 / (i + 1)))\n",
    "\n",
    "        )\n",
    "\n",
    "        batch_bar.update()\n",
    "\n",
    "        del inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if i==4: break      # validating only upon first five batches\n",
    "\n",
    "    batch_bar.close()\n",
    "    running_distance /= 5\n",
    "    running_cer /= 5\n",
    "    running_wer /= 5\n",
    "    running_char_f1 /= 5\n",
    "    running_word_f1 /= 5\n",
    "\n",
    "    return running_distance, running_cer, running_wer, running_char_f1, running_word_f1\n",
    "\n",
    "def validate_full(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    # progress bar\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc=\"Val\", ncols=5)\n",
    "\n",
    "    running_distance = 0.0\n",
    "    running_cer = 0.0\n",
    "    running_wer = 0.0\n",
    "    running_char_f1 = 0.0\n",
    "    running_word_f1 =0.0\n",
    "\n",
    "    for i, (inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths) in enumerate(dataloader):\n",
    "\n",
    "        inputs  = inputs.to(device)\n",
    "        targets_golden = targets_golden.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            greedy_predictions = model.recognize(inputs, inputs_lengths)\n",
    "\n",
    "        # calculating Levenshtein Distance\n",
    "        # @NOTE: modify the print_example to print more or less validation examples\n",
    "        dist, cer, wer, charf1, word_f1 = calc_edit_distance(greedy_predictions, targets_golden, targets_lengths, tokenizer, print_example=False)\n",
    "        running_distance += dist\n",
    "        running_cer += cer\n",
    "        running_wer += wer\n",
    "        running_char_f1 += charf1\n",
    "        running_word_f1 += word_f1\n",
    "\n",
    "\n",
    "        # online validation distance monitoring\n",
    "        batch_bar.set_postfix(\n",
    "            running_distance = \"{:.04f}\".format(float(running_distance / (i + 1))),\n",
    "            running_cer = \"{:.04f}\".format(float(running_cer / (i + 1))),\n",
    "            running_wer = \"{:.04f}\".format(float(running_wer / (i + 1))),\n",
    "            running_char_f1 = \"{:.04f}\".format(float(running_char_f1 / (i + 1))),\n",
    "            running_word_f1 = \"{:.04f}\".format(float(running_word_f1 / (i + 1)))\n",
    "\n",
    "        )\n",
    "        batch_bar.update()\n",
    "\n",
    "        del inputs, targets_shifted, targets_golden, inputs_lengths, targets_lengths\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    batch_bar.close()\n",
    "    running_distance /= len(dataloader)\n",
    "    running_cer /= len(dataloader)\n",
    "    running_wer /= len(dataloader)\n",
    "    running_char_f1 /= len(dataloader)\n",
    "    running_word_f1 /= len(dataloader)\n",
    "\n",
    "\n",
    "    return running_distance, running_cer, running_wer, running_char_f1, running_word_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723648/1907291034.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler      = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "''' defining optimizer '''\n",
    "# vocab_size = len(tokenizer)\n",
    "# weights = torch.ones(vocab_size).to(\"cuda\")  # default weight = 1 for all\n",
    "# whitespace_token_id = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(' ')[0])\n",
    "# # Decrease weight for whitespace token\n",
    "# weights[whitespace_token_id] = 0.1  # e.g., reduce impact by 90%\n",
    "loss_func   = torch.nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)\n",
    "scaler      = torch.cuda.amp.GradScaler()\n",
    "if config[\"optimizer\"] == \"SGD\":\n",
    "  # feel free to change any of the initializations you like to fit your needs\n",
    "  optimizer = torch.optim.SGD(model.parameters(),\n",
    "                              lr=config[\"learning_rate\"],\n",
    "                              momentum=config[\"momentum\"],\n",
    "                              weight_decay=1E-4,\n",
    "                              nesterov=config[\"nesterov\"])\n",
    "\n",
    "elif config[\"optimizer\"] == \"Adam\":\n",
    "  # feel free to change any of the initializations you like to fit your needs\n",
    "  optimizer = torch.optim.Adam(model.parameters(),\n",
    "                               lr=float(config[\"learning_rate\"]),\n",
    "                               weight_decay=1e-4)\n",
    "\n",
    "elif config[\"optimizer\"] == \"AdamW\":\n",
    "  # feel free to change any of the initializations you like to fit your needs\n",
    "  optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                                lr=float(config[\"learning_rate\"]),\n",
    "                                weight_decay=0.01)\n",
    "\n",
    "''' defining scheduler '''\n",
    "\n",
    "if config[\"scheduler\"] == \"ReduceLR\":\n",
    "  #Feel Free to change any of the initializations you like to fit your needs\n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                factor=config[\"factor\"], patience=config[\"patience\"], min_lr=1E-8, verbose=True)\n",
    "\n",
    "elif config[\"scheduler\"] == \"CosineAnnealing\":\n",
    "  #Feel Free to change any of the initializations you like to fit your needs\n",
    "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                T_max = 35, eta_min=1E-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mblessedg\u001b[0m (\u001b[33midls24\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/HandWritten_Amharic_English_OCR/dataset/wandb/run-20250509_093709-ulhhkkks</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/idls24/handonlyocr-cnn-lstm/runs/ulhhkkks' target=\"_blank\">blessed_Transformer_ENC-1/1_DEC-6/8_256_1024_AdamW_CosineAnnealing</a></strong> to <a href='https://wandb.ai/idls24/handonlyocr-cnn-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/idls24/handonlyocr-cnn-lstm' target=\"_blank\">https://wandb.ai/idls24/handonlyocr-cnn-lstm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/idls24/handonlyocr-cnn-lstm/runs/ulhhkkks' target=\"_blank\">https://wandb.ai/idls24/handonlyocr-cnn-lstm/runs/ulhhkkks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using WandB? resume training?\n",
    "\n",
    "USE_WANDB = config[\"USE_WANDB\"]\n",
    "RESUME_LOGGING = False\n",
    "\n",
    "# creating your WandB run\n",
    "run_name = \"{}_Transformer_ENC-{}/{}_DEC-{}/{}_{}_{}_{}_{}\".format(\n",
    "    config[\"Name\"],\n",
    "    config[\"enc_num_layers\"],       # only used in Part II with the Transformer Encoder\n",
    "    config[\"enc_num_heads\"],        # only used in Part II with the Transformer Encoder\n",
    "    config[\"dec_num_layers\"],\n",
    "    config[\"dec_num_heads\"],\n",
    "    config[\"d_model\"],\n",
    "    config[\"d_ff\"],\n",
    "    config[\"optimizer\"],\n",
    "    config[\"scheduler\"])\n",
    "task = \"handonly\"\n",
    "\n",
    "if USE_WANDB:\n",
    "\n",
    "    wandb.login(key=\"3c7b273814544590b64c54d9a5242bde38616e02\", relogin=True) # TODO enter your key here\n",
    "\n",
    "    if RESUME_LOGGING:\n",
    "        run_id = \"\"\n",
    "        run = wandb.init(\n",
    "            id     = run_id,        ### Insert specific run id here if you want to resume a previous run\n",
    "            resume = True,          ### You need this to resume previous runs, but comment out reinit=True when using this\n",
    "            project = task+\"ocr-cnn-lstm\",  ### Project should be created in your wandb account\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        run = wandb.init(\n",
    "            name    = run_name,     ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
    "            reinit  = True,         ### Allows reinitalizing runs when you re-run this cell\n",
    "            project = task+\"ocr-cnn-lstm\",  ### Project should be created in your wandb account\n",
    "            config  = config        ### Wandb Config for your run\n",
    "        )\n",
    "\n",
    "        ### Save your model architecture as a string with str(model)\n",
    "        model_arch  = str(model)\n",
    "\n",
    "        ### Save it in a txt file\n",
    "        arch_file   = open(\"model_arch.txt\", \"w\")\n",
    "        file_write  = arch_file.write(model_arch)\n",
    "        arch_file.close()\n",
    "\n",
    "        ### Log it in your wandb run with wandb.save()\n",
    "        # wandb.save(\"model_arch.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/157 [00:00<?, ?it/s]/tmp/ipykernel_723648/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50: \n",
      "Train Loss 9.7843\t Train Perplexity 18618.4882\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/50: \n",
      "Train Loss 8.9782\t Train Perplexity 7997.9891\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/50: \n",
      "Train Loss 8.7003\t Train Perplexity 6012.8503\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/50: \n",
      "Train Loss 8.6470\t Train Perplexity 5701.7316\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/50: \n",
      "Train Loss 8.6150\t Train Perplexity 5520.4645\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/50: \n",
      "Train Loss 8.5877\t Train Perplexity 5373.3749\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/50: \n",
      "Train Loss 8.5688\t Train Perplexity 5272.0441\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/50: \n",
      "Train Loss 8.5549\t Train Perplexity 5197.8645\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/50: \n",
      "Train Loss 8.5415\t Train Perplexity 5128.9682\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/50: \n",
      "Train Loss 8.5283\t Train Perplexity 5062.5420\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/50: \n",
      "Train Loss 8.5172\t Train Perplexity 5007.7997\t Learning Rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|          | 1/157 [00:23<1:01:48, 23.78s/it, running_cer=0.8787, running_char_f1=0.0919, running_distance=59.9375, running_wer=1.2971, running_word_f1=0.0072]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  የፌዴራሉ ከፍተኛ ፍርድ ቤት የነ ዘላለም ወርቅ አገኘ ሁን ፍርድ ለሌላ ጊዜ አስተላለፈ\n",
      "Prediction   :  ላይ ላይ ላይ ላይ ላይ ላይ ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 2/157 [00:45<58:40, 22.72s/it, running_cer=0.8656, running_char_f1=0.0926, running_distance=60.7812, running_wer=1.2821, running_word_f1=0.0103]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  አንድ ኩባ ያ ም ስር የፎ ሌት ፍላ ታችንን ያ ሟ ላል\n",
      "Prediction   :  ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   2%|▏         | 3/157 [01:07<57:29, 22.40s/it, running_cer=0.8785, running_char_f1=0.0937, running_distance=60.8802, running_wer=1.3099, running_word_f1=0.0093]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እሳቸው ከሥልጣን አል ወር ድም ብለው ከኢህአዴግ ጋር ሙግት ሊ ገጥ ሙ አይችሉም ይሄ ማ ውለታ ቢስ መሆን ነው እናላችሁ ሰላማዊ የስልጣን ሽግግር ከሚለው ይልቅ\n",
      "Prediction   :  ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ነው\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 4/157 [01:29<56:40, 22.22s/it, running_cer=0.8881, running_char_f1=0.0897, running_distance=60.7695, running_wer=1.3047, running_word_f1=0.0116]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ተስፋ መፈን ጠቅ በጀመረ በት ወቅት የሚካሄድ መሆኑን በማረጋገጥ ለውጡን በብቃት ለመምራት በሚያስ ችሉ የ ድርጅትና የመንግስት ሪፎርም ጉዳዮች ዙሪያ በስፋት ተወያይቶ ውሳኔዎች አሳልፏል\n",
      "Prediction   :  ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 5/157 [01:51<56:01, 22.11s/it, running_cer=0.8788, running_char_f1=0.0901, running_distance=61.4000, running_wer=1.2765, running_word_f1=0.0122]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  የኢትዮጵያ የምርጫ ቅርጫ አይን ያወጣ የቅ ጥፈት የይስሙላ ምርጫ ፕሮፌሰር አለማየሁ ገብረማርያም\n",
      "Prediction   :  ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distance training model\n",
      "Levenshtein Distance 61.4000\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/157 [00:00<?, ?it/s]/tmp/ipykernel_723648/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/50: \n",
      "Train Loss 8.5035\t Train Perplexity 4938.3547\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/50: \n",
      "Train Loss 8.4880\t Train Perplexity 4864.0745\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/50: \n",
      "Train Loss 8.4713\t Train Perplexity 4784.5364\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/50: \n",
      "Train Loss 8.4563\t Train Perplexity 4711.7348\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/50: \n",
      "Train Loss 8.4388\t Train Perplexity 4629.2968\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/50: \n",
      "Train Loss 8.4225\t Train Perplexity 4553.9536\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/50: \n",
      "Train Loss 8.4009\t Train Perplexity 4458.9761\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/50: \n",
      "Train Loss 8.3866\t Train Perplexity 4394.1271\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/50: \n",
      "Train Loss 8.3683\t Train Perplexity 4314.6737\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/50: \n",
      "Train Loss 8.3503\t Train Perplexity 4237.2750\t Learning Rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|          | 1/157 [00:23<1:01:30, 23.66s/it, running_cer=7.4763, running_char_f1=0.1007, running_distance=687.3906, running_wer=11.1243, running_word_f1=0.0033]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  የፌዴራሉ ከፍተኛ ፍርድ ቤት የነ ዘላለም ወርቅ አገኘ ሁን ፍርድ ለሌላ ጊዜ አስተላለፈ\n",
      "Prediction   :  ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ነው\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 2/157 [00:45<58:40, 22.71s/it, running_cer=7.9855, running_char_f1=0.0984, running_distance=721.8984, running_wer=11.6338, running_word_f1=0.0070]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  አንድ ኩባ ያ ም ስር የፎ ሌት ፍላ ታችንን ያ ሟ ላል\n",
      "Prediction   :  በ በ በ በ በ በ በ በ በ በ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ነው\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   2%|▏         | 3/157 [01:07<57:32, 22.42s/it, running_cer=7.8865, running_char_f1=0.0978, running_distance=711.6458, running_wer=11.5977, running_word_f1=0.0089]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እሳቸው ከሥልጣን አል ወር ድም ብለው ከኢህአዴግ ጋር ሙግት ሊ ገጥ ሙ አይችሉም ይሄ ማ ውለታ ቢስ መሆን ነው እናላችሁ ሰላማዊ የስልጣን ሽግግር ከሚለው ይልቅ\n",
      "Prediction   :  ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ላይ ላይ ላይ ላይ ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 4/157 [01:29<56:42, 22.24s/it, running_cer=7.8136, running_char_f1=0.0950, running_distance=703.4180, running_wer=11.4046, running_word_f1=0.0083]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ተስፋ መፈን ጠቅ በጀመረ በት ወቅት የሚካሄድ መሆኑን በማረጋገጥ ለውጡን በብቃት ለመምራት በሚያስ ችሉ የ ድርጅትና የመንግስት ሪፎርም ጉዳዮች ዙሪያ በስፋት ተወያይቶ ውሳኔዎች አሳልፏል\n",
      "Prediction   :  ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 5/157 [01:51<56:03, 22.13s/it, running_cer=7.9243, running_char_f1=0.0938, running_distance=719.4094, running_wer=11.5075, running_word_f1=0.0084]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  የኢትዮጵያ የምርጫ ቅርጫ አይን ያወጣ የቅ ጥፈት የይስሙላ ምርጫ ፕሮፌሰር አለማየሁ ገብረማርያም\n",
      "Prediction   :  ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distance training model\n",
      "Levenshtein Distance 719.4094\n",
      "\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/157 [00:00<?, ?it/s]/tmp/ipykernel_723648/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/50: \n",
      "Train Loss 8.3325\t Train Perplexity 4163.4318\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/50: \n",
      "Train Loss 8.3175\t Train Perplexity 4099.6091\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/50: \n",
      "Train Loss 8.2993\t Train Perplexity 4026.3960\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/50: \n",
      "Train Loss 8.2792\t Train Perplexity 3946.1936\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/50: \n",
      "Train Loss 8.2638\t Train Perplexity 3887.5140\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/50: \n",
      "Train Loss 8.2461\t Train Perplexity 3816.9675\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/50: \n",
      "Train Loss 8.2272\t Train Perplexity 3745.9910\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/50: \n",
      "Train Loss 8.2072\t Train Perplexity 3673.5812\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/50: \n",
      "Train Loss 8.1920\t Train Perplexity 3616.4856\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/50: \n",
      "Train Loss 8.1757\t Train Perplexity 3558.4326\t Learning Rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|          | 1/157 [00:23<1:01:38, 23.71s/it, running_cer=14.0718, running_char_f1=0.0965, running_distance=1040.2031, running_wer=23.7411, running_word_f1=0.0021]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  የፌዴራሉ ከፍተኛ ፍርድ ቤት የነ ዘላለም ወርቅ አገኘ ሁን ፍርድ ለሌላ ጊዜ አስተላለፈ\n",
      "Prediction   :  በ በ በ በ በ በ ከ ከ ከ ከ ከ ከ ከ ከ ከ ከ ከ ከ ከ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 2/157 [00:45<58:32, 22.66s/it, running_cer=14.4737, running_char_f1=0.0998, running_distance=1068.2266, running_wer=23.6961, running_word_f1=0.0079]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  አንድ ኩባ ያ ም ስር የፎ ሌት ፍላ ታችንን ያ ሟ ላል\n",
      "Prediction   :  በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   2%|▏         | 3/157 [01:07<57:24, 22.36s/it, running_cer=14.6824, running_char_f1=0.1015, running_distance=1070.2865, running_wer=24.3629, running_word_f1=0.0079]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እሳቸው ከሥልጣን አል ወር ድም ብለው ከኢህአዴግ ጋር ሙግት ሊ ገጥ ሙ አይችሉም ይሄ ማ ውለታ ቢስ መሆን ነው እናላችሁ ሰላማዊ የስልጣን ሽግግር ከሚለው ይልቅ\n",
      "Prediction   :  ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው ነው\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 4/157 [01:29<56:36, 22.20s/it, running_cer=14.2296, running_char_f1=0.1022, running_distance=1045.1523, running_wer=23.6270, running_word_f1=0.0095]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ተስፋ መፈን ጠቅ በጀመረ በት ወቅት የሚካሄድ መሆኑን በማረጋገጥ ለውጡን በብቃት ለመምራት በሚያስ ችሉ የ ድርጅትና የመንግስት ሪፎርም ጉዳዮች ዙሪያ በስፋት ተወያይቶ ውሳኔዎች አሳልፏል\n",
      "Prediction   :  ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 5/157 [01:51<56:06, 22.15s/it, running_cer=14.3027, running_char_f1=0.1014, running_distance=1061.6531, running_wer=23.2907, running_word_f1=0.0088]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  የኢትዮጵያ የምርጫ ቅርጫ አይን ያወጣ የቅ ጥፈት የይስሙላ ምርጫ ፕሮፌሰር አለማየሁ ገብረማርያም\n",
      "Prediction   :  በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distance training model\n",
      "Levenshtein Distance 1061.6531\n",
      "\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/157 [00:00<?, ?it/s]/tmp/ipykernel_723648/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/50: \n",
      "Train Loss 8.1557\t Train Perplexity 3487.1047\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/50: \n",
      "Train Loss 8.1376\t Train Perplexity 3426.2059\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/50: \n",
      "Train Loss 8.1144\t Train Perplexity 3347.6527\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/50: \n",
      "Train Loss 8.0973\t Train Perplexity 3290.6567\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/50: \n",
      "Train Loss 8.0784\t Train Perplexity 3228.7956\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/50: \n",
      "Train Loss 8.0593\t Train Perplexity 3167.3402\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/50: \n",
      "Train Loss 8.0335\t Train Perplexity 3087.6114\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/50: \n",
      "Train Loss 8.0110\t Train Perplexity 3018.1615\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/50: \n",
      "Train Loss 7.9893\t Train Perplexity 2953.1720\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41/50: \n",
      "Train Loss 7.9665\t Train Perplexity 2885.9148\t Learning Rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|          | 1/157 [00:28<1:13:38, 28.32s/it, running_cer=13.3437, running_char_f1=0.1058, running_distance=961.8125, running_wer=20.8368, running_word_f1=0.0041]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  የፌዴራሉ ከፍተኛ ፍርድ ቤት የነ ዘላለም ወርቅ አገኘ ሁን ፍርድ ለሌላ ጊዜ አስተላለፈ\n",
      "Prediction   :  በ በ በ በ በ ከ ከ ከ እና እና እና እና እና ላይ ላይ ላይ ላይ ላይ ላይ ላይ ኣብ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   1%|▏         | 2/157 [00:50<1:03:28, 24.57s/it, running_cer=14.6178, running_char_f1=0.1046, running_distance=1040.5547, running_wer=22.1573, running_word_f1=0.0066]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  አንድ ኩባ ያ ም ስር የፎ ሌት ፍላ ታችንን ያ ሟ ላል\n",
      "Prediction   :  በ በ በ ላይ እና እና ና ና ላይ ላይ ላይ ላይ ላይ ላይ ነበር\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   2%|▏         | 3/157 [01:12<59:58, 23.37s/it, running_cer=15.0672, running_char_f1=0.1059, running_distance=1058.1875, running_wer=23.2942, running_word_f1=0.0085]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  እሳቸው ከሥልጣን አል ወር ድም ብለው ከኢህአዴግ ጋር ሙግት ሊ ገጥ ሙ አይችሉም ይሄ ማ ውለታ ቢስ መሆን ነው እናላችሁ ሰላማዊ የስልጣን ሽግግር ከሚለው ይልቅ\n",
      "Prediction   :  ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ ላይ እና እና እና እና በ በ በ በ በ በ በ በ በ በ በ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ ይህ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 4/157 [01:34<58:11, 22.82s/it, running_cer=14.7722, running_char_f1=0.1061, running_distance=1042.1133, running_wer=22.9096, running_word_f1=0.0119]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  ተስፋ መፈን ጠቅ በጀመረ በት ወቅት የሚካሄድ መሆኑን በማረጋገጥ ለውጡን በብቃት ለመምራት በሚያስ ችሉ የ ድርጅትና የመንግስት ሪፎርም ጉዳዮች ዙሪያ በስፋት ተወያይቶ ውሳኔዎች አሳልፏል\n",
      "Prediction   :  የኢትዮጵያ የኢትዮጵያ ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ የኢትዮጵያ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   3%|▎         | 5/157 [01:56<57:07, 22.55s/it, running_cer=15.1143, running_char_f1=0.1060, running_distance=1071.8844, running_wer=23.0131, running_word_f1=0.0104]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground Truth :  የኢትዮጵያ የምርጫ ቅርጫ አይን ያወጣ የቅ ጥፈት የይስሙላ ምርጫ ፕሮፌሰር አለማየሁ ገብረማርያም\n",
      "Prediction   :  በ በ በ ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና ና በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ ና ና ና ና ና ና ና በ በ በ ና ና ና ና ና ና ና ና በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ በ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distance training model\n",
      "Levenshtein Distance 1071.8844\n",
      "\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/157 [00:00<?, ?it/s]/tmp/ipykernel_723648/3134595652.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/50: \n",
      "Train Loss 7.9464\t Train Perplexity 2828.8251\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43/50: \n",
      "Train Loss 7.9227\t Train Perplexity 2762.6874\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/50: \n",
      "Train Loss 7.8983\t Train Perplexity 2696.0380\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/50: \n",
      "Train Loss 7.8771\t Train Perplexity 2639.6320\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/50: \n",
      "Train Loss 7.8499\t Train Perplexity 2568.9983\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/50: \n",
      "Train Loss 7.8248\t Train Perplexity 2505.1422\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48/50: \n",
      "Train Loss 7.7956\t Train Perplexity 2434.6505\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49/50: \n",
      "Train Loss 7.7748\t Train Perplexity 2383.0033\t Learning Rate 0.0001\n",
      "\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/50: \n",
      "Train Loss 7.7462\t Train Perplexity 2315.4593\t Learning Rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "e                   = 0\n",
    "best_loss           = 0\n",
    "best_distance  = 0\n",
    "checkpoint_root = os.path.join(os.getcwd(), \"checkpoints-basic-cnn-transformer\")\n",
    "os.makedirs(checkpoint_root, exist_ok=True)\n",
    "if USE_WANDB:\n",
    "    wandb.watch(model, log=\"all\")\n",
    "task =  config[\"TRAIN_TASK\"]\n",
    "checkpoint_best_loss_model_filename     = task +'checkpoint-best-loss-model.pth' \n",
    "checkpoint_best_distance_model_filename     = task +'checkpoint-best-distance-model.pth'\n",
    "\n",
    "checkpoint_last_epoch_filename          = 'checkpoint-epoch-'\n",
    "best_loss_model_path                    = os.path.join(checkpoint_root, checkpoint_best_loss_model_filename)\n",
    "best_distance_model_path                    = os.path.join(checkpoint_root, checkpoint_best_distance_model_filename)\n",
    "\n",
    "\n",
    "if RESUME_LOGGING:\n",
    "    # change if you want to load best test model accordingly\n",
    "    checkpoint = torch.load(wandb.restore(checkpoint_best_loss_model_filename, run_path=\"\"+run_id).name)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    e = checkpoint['epoch']\n",
    "\n",
    "    print(\"Resuming from epoch {}\".format(e+1))\n",
    "    print(\"Epochs left: \", config['epochs']-e)\n",
    "    print(\"Optimizer: \\n\", optimizer)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "epochs = config[\"epochs\"]\n",
    "for epoch in range(e, epochs):\n",
    "\n",
    "    print(\"\\nEpoch {}/{}\".format(epoch+1, config[\"epochs\"]))\n",
    "\n",
    "    curr_lr = float(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    train_loss, train_perplexity, attention_weights = train_model(model, train_loader, optimizer)\n",
    "\n",
    "    print(\"\\nEpoch {}/{}: \\nTrain Loss {:.04f}\\t Train Perplexity {:.04f}\\t Learning Rate {:.04f}\".format(\n",
    "        epoch + 1, config[\"epochs\"], train_loss, train_perplexity, curr_lr))\n",
    "\n",
    "    if (epoch >1 )and (epoch % 10 == 0):    # validate every 2 epochs to speed up training\n",
    "        levenshtein_distance, cer, wer, charf1, wordf1 = validate_fast(model, val_loader)\n",
    "        if best_distance <= levenshtein_distance:\n",
    "            best_distance = levenshtein_distance\n",
    "            save_model(model, optimizer, scheduler, ['val_distance', levenshtein_distance], epoch, best_distance_model_path)\n",
    "            # wandb.save(best_loss_model_path)\n",
    "            print(\"Saved distance training model\")\n",
    "        print(\"Levenshtein Distance {:.04f}\".format(levenshtein_distance))\n",
    "        if USE_WANDB:\n",
    "            wandb.log({\"train_loss\"     : train_loss,\n",
    "                    \"train_perplexity\"  : train_perplexity,\n",
    "                    \"learning_rate\"     : curr_lr,\n",
    "                    \"val_distance\"      : levenshtein_distance,\n",
    "                    \"charf1\": charf1,\n",
    "                    \"wordf1\": wordf1,})\n",
    "\n",
    "    else:\n",
    "        if USE_WANDB:\n",
    "\n",
    "            wandb.log({\"train_loss\"     : train_loss,\n",
    "                    \"train_perplexity\"  : train_perplexity,\n",
    "                    \"learning_rate\"     : curr_lr})\n",
    "\n",
    "    # # plotting the encoder-nearest and decoder-nearest attention weights\n",
    "    # attention_keys = list(attention_weights.keys())\n",
    "\n",
    "    # attention_weights_decoder_self       = attention_weights[attention_keys[0]][0].cpu().detach().numpy()\n",
    "    # attention_weights_decoder_cross      = attention_weights[attention_keys[-1]][0].cpu().detach().numpy()\n",
    "\n",
    "    # # saving the cross-attention weights\n",
    "    # save_attention_plot(attention_weights_decoder_cross, epoch+100)\n",
    "\n",
    "    # plot_attention_weights((attention_weights[attention_keys[0]][0]).cpu().detach().numpy())\n",
    "    # plot_attention_weights(attention_weights[attention_keys[-1]][0].cpu().detach().numpy())\n",
    "\n",
    "    # if config[\"scheduler\"] == \"ReduceLR\":\n",
    "    #     scheduler.step(levenshtein_distance)\n",
    "    # else:\n",
    "    #     scheduler.step()\n",
    "\n",
    "    # ### Highly Recommended: Save checkpoint in drive and/or wandb if accuracy is better than your current best\n",
    "    # epoch_model_path = os.path.join(checkpoint_root, (checkpoint_last_epoch_filename + str(epoch) + '.pth'))\n",
    "    # save_model(model, optimizer, scheduler, ['train_loss', train_loss], epoch, epoch_model_path)\n",
    "    ## wandb.save(epoch_model_path) ## Can't save on wandb for all epochs, may blow up storage\n",
    "\n",
    "\n",
    "    if best_loss >= train_loss:\n",
    "        best_loss = train_loss\n",
    "        save_model(model, optimizer, scheduler, ['train_loss', train_loss], epoch, best_loss_model_path)\n",
    "        # wandb.save(best_loss_model_path)\n",
    "        print(\"Saved best training model\")\n",
    "\n",
    "### Finish your wandb run\n",
    "# run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNTHETIC is been evaluated on HANDWRITTEN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   6%|▌         | 9/157 [03:19<54:24, 22.06s/it, running_cer=27.4220, running_char_f1=0.1048, running_distance=1381.8611, running_wer=36.0575, running_word_f1=0.0057]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     10\u001b[39m val_data = MyCustomOcrDataloader(VAL_PATH, preprocessor=processor, tokenizer  = tokenizer, img_root=IMG_ROOT)\n\u001b[32m     11\u001b[39m val_loader      = torch.utils.data.DataLoader(\n\u001b[32m     12\u001b[39m dataset     = val_data,\n\u001b[32m     13\u001b[39m batch_size  = config[\u001b[33m\"\u001b[39m\u001b[33mBATCH_SIZE\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m collate_fn  = train_data.collate_fn,\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m levenshtein_distance, cer, wer, charf1, wordf1 = \u001b[43mvalidate_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m result[task]  = {}\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metric, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m ([\u001b[33m\"\u001b[39m\u001b[33mlev\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcharf1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwordf1\u001b[39m\u001b[33m\"\u001b[39m], [levenshtein_distance, cer, wer, charf1, wordf1]):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mvalidate_full\u001b[39m\u001b[34m(model, dataloader)\u001b[39m\n\u001b[32m     73\u001b[39m targets_golden = targets_golden.to(device)\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     greedy_predictions = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# calculating Levenshtein Distance\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# @NOTE: modify the print_example to print more or less validation examples\u001b[39;00m\n\u001b[32m     80\u001b[39m dist, cer, wer, charf1, word_f1 = calc_edit_distance(greedy_predictions, targets_golden, targets_lengths, tokenizer, print_example=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HandWritten_Amharic_English_OCR/experiments/../models/models.py:68\u001b[39m, in \u001b[36mTrOCRMyDecoder.recognize\u001b[39m\u001b[34m(self, inp, inp_len)\u001b[39m\n\u001b[32m     66\u001b[39m encoder_output                = \u001b[38;5;28mself\u001b[39m.proj(encoder_output)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# out                            = self.decoder.recognize_beam_search(encoder_output, encoder_lens,beam_width=10)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m out                            = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecognize_greedy_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_lens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HandWritten_Amharic_English_OCR/experiments/../models/models.py:164\u001b[39m, in \u001b[36mDecoder.recognize_greedy_search\u001b[39m\u001b[34m(self, enc_outputs, enc_input_lengths)\u001b[39m\n\u001b[32m    161\u001b[39m     finished |= eos_mask\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# end if all sequences have generated the EOS token\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m finished.all(): \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# remove the initial <SOS> token and pad sequences to the same length\u001b[39;00m\n\u001b[32m    167\u001b[39m target_seq = target_seq[:, \u001b[32m1\u001b[39m:]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#### sweeper eval\n",
    "checkpoint = torch.load(best_distance_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "result = {}\n",
    "for task in [\"HANDWRITTEN\", \"SYNTHETIC\", \"TYPED\"]:\n",
    "    print(f\"{config[\"TRAIN_TASK\"]} is been evaluated on {task}\")\n",
    "    VAL_PATH =config[task+\"_VAL_PATH\"]\n",
    "    IMG_ROOT = config[task+\"_IMG_ROOT\"]\n",
    "\n",
    "    val_data = MyCustomOcrDataloader(VAL_PATH, preprocessor=processor, tokenizer  = tokenizer, img_root=IMG_ROOT)\n",
    "    val_loader      = torch.utils.data.DataLoader(\n",
    "    dataset     = val_data,\n",
    "    batch_size  = config[\"BATCH_SIZE\"],\n",
    "    shuffle     = False,\n",
    "    num_workers = 2,\n",
    "    pin_memory  = True,\n",
    "    collate_fn  = train_data.collate_fn,\n",
    "    )\n",
    "    levenshtein_distance, cer, wer, charf1, wordf1 = validate_full(model, val_loader)\n",
    "    result[task]  = {}\n",
    "    for metric, score in zip ([\"lev\", \"cer\", \"wer\", \"charf1\", \"wordf1\"], [levenshtein_distance, cer, wer, charf1, wordf1]):\n",
    "        result[task][metric] = score\n",
    "\n",
    "    with open(f\"result{config[\"TRAIN_TASK\"]}_.json\", 'w') as file:\n",
    "        json.dump(result, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
